{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading normal_tissue.tsv.zip...\n",
      "normal_tissue.tsv.zip downloaded!\n",
      "Downloading pathology.tsv.zip...\n",
      "pathology.tsv.zip downloaded!\n",
      "Downloading subcellular_location.tsv.zip...\n",
      "subcellular_location.tsv.zip downloaded!\n",
      "Downloading rna_tissue_consensus.tsv.zip...\n",
      "rna_tissue_consensus.tsv.zip downloaded!\n",
      "Downloading rna_tissue_hpa.tsv.zip...\n",
      "rna_tissue_hpa.tsv.zip downloaded!\n",
      "Downloading rna_tissue_hpa_description.tsv.zip...\n",
      "rna_tissue_hpa_description.tsv.zip downloaded!\n",
      "Downloading rna_brain_hpa.tsv.zip...\n",
      "rna_brain_hpa.tsv.zip downloaded!\n",
      "Downloading rna_pfc_brain_hpa.tsv.zip...\n",
      "rna_pfc_brain_hpa.tsv.zip downloaded!\n",
      "Downloading rna_tissue_gtex.tsv.zip...\n",
      "rna_tissue_gtex.tsv.zip downloaded!\n",
      "Downloading rna_tissue_fantom.tsv.zip...\n",
      "rna_tissue_fantom.tsv.zip downloaded!\n",
      "Downloading rna_single_cell_type.tsv.zip...\n",
      "rna_single_cell_type.tsv.zip downloaded!\n",
      "Downloading rna_single_cell_type_tissue.tsv.zip...\n",
      "rna_single_cell_type_tissue.tsv.zip downloaded!\n",
      "Downloading rna_single_cell_cluster_description.tsv.zip...\n",
      "rna_single_cell_cluster_description.tsv.zip downloaded!\n",
      "Skipping rna_single_cell_read_count.zip as it exceeds the size limit.\n",
      "Downloading rna_brain_gtex.tsv.zip...\n",
      "rna_brain_gtex.tsv.zip downloaded!\n",
      "Downloading rna_brain_fantom.tsv.zip...\n",
      "rna_brain_fantom.tsv.zip downloaded!\n",
      "Downloading rna_pig_brain_hpa.tsv.zip...\n",
      "rna_pig_brain_hpa.tsv.zip downloaded!\n",
      "Downloading rna_pig_brain_sample_hpa.tsv.zip...\n",
      "rna_pig_brain_sample_hpa.tsv.zip downloaded!\n",
      "Downloading rna_mouse_brain_hpa.tsv.zip...\n",
      "rna_mouse_brain_hpa.tsv.zip downloaded!\n",
      "Downloading rna_mouse_brain_sample_hpa.tsv.zip...\n",
      "rna_mouse_brain_sample_hpa.tsv.zip downloaded!\n",
      "Downloading rna_mouse_brain_allen.tsv.zip...\n",
      "rna_mouse_brain_allen.tsv.zip downloaded!\n",
      "Downloading rna_immune_cell.tsv.zip...\n",
      "rna_immune_cell.tsv.zip downloaded!\n",
      "Downloading rna_immune_cell_sample.tsv.zip...\n",
      "rna_immune_cell_sample.tsv.zip downloaded!\n",
      "Downloading rna_immune_cell_sample_tpm_m.tsv.zip...\n",
      "rna_immune_cell_sample_tpm_m.tsv.zip downloaded!\n",
      "Downloading rna_immune_cell_monaco.tsv.zip...\n",
      "rna_immune_cell_monaco.tsv.zip downloaded!\n",
      "Downloading rna_immune_cell_schmiedel.tsv.zip...\n",
      "rna_immune_cell_schmiedel.tsv.zip downloaded!\n",
      "Downloading rna_celline_cancer.tsv.zip...\n",
      "rna_celline_cancer.tsv.zip downloaded!\n",
      "Downloading rna_celline.tsv.zip...\n",
      "rna_celline.tsv.zip downloaded!\n",
      "Downloading rna_celline_description.tsv.zip...\n",
      "rna_celline_description.tsv.zip downloaded!\n",
      "Skipping rna_cancer_sample.tsv.zip as it exceeds the size limit.\n",
      "Downloading transcript_rna_tissue.tsv.zip...\n",
      "transcript_rna_tissue.tsv.zip downloaded!\n",
      "Skipping transcript_rna_brain.tsv.zip as it exceeds the size limit.\n",
      "Downloading transcript_rna_gtexretina.tsv.zip...\n",
      "transcript_rna_gtexretina.tsv.zip downloaded!\n",
      "Downloading transcript_rna_immunecells.tsv.zip...\n",
      "transcript_rna_immunecells.tsv.zip downloaded!\n",
      "Downloading transcript_rna_pigbrain.tsv.zip...\n",
      "transcript_rna_pigbrain.tsv.zip downloaded!\n",
      "Downloading transcript_rna_mousebrain.tsv.zip...\n",
      "transcript_rna_mousebrain.tsv.zip downloaded!\n",
      "Downloading proteinatlas.tsv.zip...\n",
      "proteinatlas.tsv.zip downloaded!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os # yes or no\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_files_from_hpa(url, max_size_gb=1, subfolder=\"downloads\"):\n",
    "    # Create the subfolder if it doesn't exist\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "\n",
    "    # Convert the max size from GB to bytes\n",
    "    max_size_bytes = max_size_gb * 1e9\n",
    "\n",
    "    # Make an HTTP GET request to the provided URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure we got a successful response\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Search for all <a> tags with the specified href structure\n",
    "    links = soup.find_all('a', href=True)\n",
    "\n",
    "    # Base URL to prepend to relative file paths\n",
    "    base_url = \"https://www.proteinatlas.org\"\n",
    "\n",
    "    for link in links:\n",
    "        file_url = link['href']\n",
    "        if file_url.endswith('.zip'):  # Check if the link is to a .zip file\n",
    "            full_url = base_url + file_url\n",
    "\n",
    "            # Extract filename from the URL\n",
    "            filename = file_url.split('/')[-1]\n",
    "\n",
    "            # Create the full path to save the file\n",
    "            save_path = os.path.join(subfolder, filename)\n",
    "\n",
    "            # Check if the file already exists\n",
    "            if os.path.exists(save_path):\n",
    "                print(f\"{filename} already exists. Skipping download.\")\n",
    "                continue\n",
    "\n",
    "            # Check file size without downloading the entire file\n",
    "            file_response = requests.head(full_url)\n",
    "            file_size = int(file_response.headers.get('Content-Length', 0))\n",
    "\n",
    "            if file_size <= max_size_bytes:\n",
    "                # Download the file if it's within the size limit\n",
    "                print(f\"Downloading {filename}...\")\n",
    "                file_response = requests.get(full_url, stream=True)\n",
    "                with open(save_path, 'wb') as file:\n",
    "                    for chunk in file_response.iter_content(chunk_size=8192):\n",
    "                        file.write(chunk)\n",
    "                print(f\"{filename} downloaded!\")\n",
    "            else:\n",
    "                print(f\"Skipping {filename} as it exceeds the size limit.\")\n",
    "\n",
    "# Example usage\n",
    "download_files_from_hpa(\"https://www.proteinatlas.org/about/download\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipped_folder/normal_tissue.tsv already exists, skipping unzip.\n",
      "Sorted data saved to sorted_data/sorted_normal_tissue.tsv\n",
      "Unzipped files to unzipped_folder\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Cell type'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m unzip_file_if_not_exists(zip_file_path, \u001b[39m'\u001b[39m\u001b[39munzipped_folder\u001b[39m\u001b[39m'\u001b[39m, target_file_path)\n\u001b[1;32m     43\u001b[0m \u001b[39m# Process and sort the TSV file\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m process_and_sort_tsv(target_file_path, output_file_path)\n",
      "Cell \u001b[0;32mIn[21], line 22\u001b[0m, in \u001b[0;36mprocess_and_sort_tsv\u001b[0;34m(input_file_path, output_file_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(input_file_path, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Extract the 'Gene' and 'Cell type' columns\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m extracted_df \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39;49m\u001b[39mGene\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCell type\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[1;32m     24\u001b[0m \u001b[39m# Sort by 'Cell type'\u001b[39;00m\n\u001b[1;32m     25\u001b[0m sorted_df \u001b[39m=\u001b[39m extracted_df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCell type\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pandas/core/frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3900\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3901\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3902\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3904\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pandas/core/indexes/base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pandas/core/indexes/base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Cell type'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip_file_if_not_exists(zip_file_path, output_folder_path, target_file_path):\n",
    "    # Check if the ZIP file exists in the 'downloads' folder\n",
    "    if not os.path.exists(zip_file_path):\n",
    "        print(f\"{zip_file_path} does not exist. Skipping unzip.\")\n",
    "        return\n",
    "\n",
    "    # Check if the target file already exists\n",
    "    if not os.path.exists(target_file_path):\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_folder_path)\n",
    "            print(f\"Unzipped files to {output_folder_path}\")\n",
    "    else:\n",
    "        print(f\"{target_file_path} already exists, skipping unzip.\")\n",
    "\n",
    "def process_and_sort_tsv(input_file_path, output_file_path):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_directory = os.path.dirname(output_file_path)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Read the tsv file into a DataFrame\n",
    "    df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "    # Extract the 'Gene' and 'Cell type' columns\n",
    "    extracted_df = df[['Gene', 'Cell type']]\n",
    "\n",
    "    # Sort by 'Cell type'\n",
    "    sorted_df = extracted_df.sort_values(by='Cell type')\n",
    "    \n",
    "    # Save the sorted data to a new .tsv file\n",
    "    sorted_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "    print(f\"Sorted data saved to {output_file_path}\")\n",
    "\n",
    "# List of TSV files to process\n",
    "file_names = ['normal_tissue', 'rna_immune_cell', 'rna_single_cell_type', 'rna_single_cell_type_tissue']\n",
    "\n",
    "# Loop to handle each file\n",
    "for file_name in file_names:\n",
    "    zip_file_path = f\"downloads/{file_name}.tsv.zip\"\n",
    "    target_file_path = f\"unzipped_folder/{file_name}.tsv\"\n",
    "    output_file_path = f\"sorted_data/sorted_{file_name}.tsv\"\n",
    "\n",
    "    # Check if the file exists, if not then unzip\n",
    "    unzip_file_if_not_exists(zip_file_path, 'unzipped_folder', target_file_path)\n",
    "    \n",
    "    # If the target file exists, process and sort the TSV file\n",
    "    if os.path.exists(target_file_path):\n",
    "        process_and_sort_tsv(target_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipped_folder/normal_tissue.tsv already exists, skipping unzip.\n",
      "sorted_data/sorted_normal_tissue.tsv already exists, skipping sorting.\n",
      "unzipped_folder/rna_single_cell_type.tsv already exists, skipping unzip.\n",
      "sorted_data/sorted_rna_single_cell_type.tsv already exists, skipping sorting.\n",
      "unzipped_folder/rna_single_cell_type_tissue.tsv already exists, skipping unzip.\n",
      "sorted_data/sorted_rna_single_cell_type_tissue.tsv already exists, skipping sorting.\n",
      "unzipped_folder/rna_immune_cell.tsv already exists, skipping unzip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted data saved to sorted_data/sorted_rna_immune_cell.tsv\n",
      "unzipped_folder/rna_immune_cell_schmiedel.tsv already exists, skipping unzip.\n",
      "Sorted data saved to sorted_data/sorted_rna_immune_cell_schmiedel.tsv\n",
      "unzipped_folder/rna_immune_cell_monaco.tsv already exists, skipping unzip.\n",
      "Sorted data saved to sorted_data/sorted_rna_immune_cell_monaco.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip_file_if_not_exists(zip_file_path, output_folder_path, target_file_path):\n",
    "    if not os.path.exists(target_file_path):\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_folder_path)\n",
    "            print(f\"Unzipped files to {output_folder_path}\")\n",
    "    else:\n",
    "        print(f\"{target_file_path} already exists, skipping unzip.\")\n",
    "\n",
    "def process_and_sort_tsv(input_file_path, output_file_path, cell_type_column):\n",
    "    # Check if the sorted file already exists\n",
    "    if os.path.exists(output_file_path):\n",
    "        print(f\"{output_file_path} already exists, skipping sorting.\")\n",
    "        return\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_directory = os.path.dirname(output_file_path)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Read the tsv file into a DataFrame\n",
    "    df = pd.read_csv(input_file_path, sep='\\t')\n",
    "\n",
    "    # Make column names case-insensitive and strip extra spaces\n",
    "    normalized_columns = {col.strip().lower(): col for col in df.columns}\n",
    "\n",
    "    try:\n",
    "        # Extract the 'Gene' and cell_type_column columns\n",
    "        actual_cell_type_column = normalized_columns.get(cell_type_column.lower())\n",
    "        extracted_df = df[['Gene', actual_cell_type_column]]\n",
    "\n",
    "        # Sort by cell_type_column\n",
    "        sorted_df = extracted_df.sort_values(by=actual_cell_type_column)\n",
    "        \n",
    "        # Save the sorted data to a new .tsv file\n",
    "        sorted_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "        print(f\"Sorted data saved to {output_file_path}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Could not find column: {e}\")\n",
    "        print(f\"Available columns in the DataFrame: {df.columns.tolist()}\")\n",
    "\n",
    "# List of TSV files to process\n",
    "file_names = [\n",
    "    {'name': 'normal_tissue', 'cell_type_column': 'Cell type'},\n",
    "    {'name': 'rna_single_cell_type', 'cell_type_column': 'Cell type'},\n",
    "    {'name': 'rna_single_cell_type_tissue', 'cell_type_column': 'Immune cell'},\n",
    "    {'name': 'rna_immune_cell', 'cell_type_column': 'Immune cell'},\n",
    "    {'name': 'rna_immune_cell_schmiedel', 'cell_type_column': 'Immune cell'},\n",
    "    {'name': 'rna_immune_cell_monaco', 'cell_type_column': 'Immune cell'}\n",
    "]\n",
    "\n",
    "# Loop to handle each file\n",
    "for file_info in file_names:\n",
    "    file_name = file_info['name']\n",
    "    cell_type_column = file_info['cell_type_column']\n",
    "    zip_file_path = f\"{file_name}.tsv.zip\"\n",
    "    target_file_path = f\"unzipped_folder/{file_name}.tsv\"\n",
    "    output_file_path = f\"sorted_data/sorted_{file_name}.tsv\"\n",
    "\n",
    "    # Check if the file exists, if not then unzip\n",
    "    unzip_file_if_not_exists(zip_file_path, 'unzipped_folder', target_file_path)\n",
    "    \n",
    "    # Process and sort the TSV file\n",
    "    process_and_sort_tsv(target_file_path, output_file_path, cell_type_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: sorted_data/sorted_normal_tissue.tsv\n",
      "Reading file: sorted_data/sorted_rna_single_cell_type.tsv\n",
      "Reading file: sorted_data/sorted_rna_single_cell_type_tissue.tsv\n",
      "Reading file: sorted_data/rna_immune_cell.tsv\n",
      "Reading file: sorted_data/sorted_rna_immune_cell.tsv\n",
      "Reading file: sorted_data/sorted_rna_immune_cell_schmiedel.tsv\n",
      "Reading file: sorted_data/sorted_rna_immune_cell_monaco.tsv\n",
      "Ensembl Gene IDs by cell type from all files written to: sorted_data/aggregated_ensembl_gene_ids_by_cell_type.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Directory containing the sorted .tsv files\n",
    "directory = \"sorted_data\"\n",
    "\n",
    "# Initialize a dictionary to hold unique Ensembl Gene IDs for each cell type\n",
    "ensembl_gene_ids_by_cell_type = {}\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    # Check if the entry is a file and has a .tsv extension\n",
    "    if os.path.isfile(filepath) and filename.endswith('.tsv'):\n",
    "        print(f\"Reading file: {filepath}\")\n",
    "        \n",
    "        # Read the .tsv file into a DataFrame\n",
    "        df = pd.read_csv(filepath, sep='\\t')\n",
    "        \n",
    "        # Drop rows where 'Gene' is NaN\n",
    "        df = df[df['Gene'].notna()]\n",
    "        \n",
    "        # Assuming that the second column is the \"Cell type\" column\n",
    "        cell_type_column = df.columns[1]\n",
    "        \n",
    "        # Group by 'Cell type' and aggregate unique 'Gene' values\n",
    "        grouped_df = df.groupby(cell_type_column)['Gene'].unique()\n",
    "        \n",
    "        # Merge the current file's grouping into the overall dictionary\n",
    "        for cell_type, gene_ids in grouped_df.items():\n",
    "            if cell_type in ensembl_gene_ids_by_cell_type:\n",
    "                ensembl_gene_ids_by_cell_type[cell_type] = list(set(ensembl_gene_ids_by_cell_type[cell_type] + list(gene_ids)))\n",
    "            else:\n",
    "                ensembl_gene_ids_by_cell_type[cell_type] = list(gene_ids)\n",
    "\n",
    "# Save the aggregated results to a JSON file\n",
    "output_path = os.path.join(directory, \"aggregated_ensembl_gene_ids_by_cell_type.json\")\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump(ensembl_gene_ids_by_cell_type, json_file)\n",
    "\n",
    "print(f\"Ensembl Gene IDs by cell type from all files written to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
