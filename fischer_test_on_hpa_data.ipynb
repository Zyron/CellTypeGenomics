{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proteinatlas.tsv.zip already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os # yes or no\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_files_from_hpa(url, max_size_gb=1, subfolder=\"downloaded_hpa_files\"):\n",
    "    # Create the subfolder if it doesn't exist\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "\n",
    "    # Convert the max size from GB to bytes\n",
    "    max_size_bytes = max_size_gb * 1e9\n",
    "\n",
    "    # Make an HTTP GET request to the provided URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure we got a successful response\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Search for all <a> tags with the specified href structure\n",
    "    links = soup.find_all('a', href=True)\n",
    "\n",
    "    # Base URL to prepend to relative file paths\n",
    "    base_url = \"https://www.proteinatlas.org\"\n",
    "\n",
    "    for link in links:\n",
    "        file_url = link['href']\n",
    "        if file_url.endswith('.zip'):  # Check if the link is to a .zip file\n",
    "            full_url = base_url + file_url\n",
    "\n",
    "            # Extract filename from the URL\n",
    "            filename = file_url.split('/')[-1]\n",
    "\n",
    "            # Create the full path to save the file\n",
    "            save_path = os.path.join(subfolder, filename)\n",
    "            \n",
    "            # Check if the file already exists\n",
    "            if os.path.exists(save_path):\n",
    "                print(f\"{filename} already exists. Skipping download.\")\n",
    "                continue\n",
    "\n",
    "            if filename == \"proteinatlas.tsv.zip\":\n",
    "                # Check file size without downloading the entire file\n",
    "                file_response = requests.head(full_url)\n",
    "                file_size = int(file_response.headers.get('Content-Length', 0))\n",
    "\n",
    "                if file_size <= max_size_bytes:\n",
    "                    # Download the file if it's within the size limit\n",
    "                    print(f\"Downloading {filename}...\")\n",
    "                    file_response = requests.get(full_url, stream=True)\n",
    "                    with open(save_path, 'wb') as file:\n",
    "                        for chunk in file_response.iter_content(chunk_size=8192):\n",
    "                            file.write(chunk)\n",
    "                    print(f\"{filename} downloaded!\")\n",
    "                else:\n",
    "                    print(f\"Skipping {filename} as it exceeds the size limit.\")\n",
    "\n",
    "# Example usage\n",
    "download_files_from_hpa(\"https://www.proteinatlas.org/about/download\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped files to unzipped_folder\n",
      "Gene,\"Gene synonym\",Ensembl,\"Gene description\",Uniprot,Chromosome,Position,\"Protein class\",\"Biological process\",\"Molecular function\",\"Disease involvement\",Evidence,\"HPA evidence\",\"UniProt evidence\",\"NeXtProt evidence\",\"RNA tissue specificity\",\"RNA tissue distribution\",\"RNA tissue specificity score\",\"RNA tissue specific nTPM\",\"RNA single cell type specificity\",\"RNA single cell type distribution\",\"RNA single cell type specificity score\",\"RNA single cell type specific nTPM\",\"RNA cancer specificity\",\"RNA cancer distribution\",\"RNA cancer specificity score\",\"RNA cancer specific FPKM\",\"RNA brain regional specificity\",\"RNA brain regional distribution\",\"RNA brain regional specificity score\",\"RNA brain regional specific nTPM\",\"RNA blood cell specificity\",\"RNA blood cell distribution\",\"RNA blood cell specificity score\",\"RNA blood cell specific nTPM\",\"RNA blood lineage specificity\",\"RNA blood lineage distribution\",\"RNA blood lineage specificity score\",\"RNA blood lineage specific nTPM\",\"RNA cell line specificity\",\"RNA cell line distribution\",\"RNA cell line specificity score\",\"RNA cell line specific nTPM\",\"RNA tissue cell type enrichment\",\"RNA mouse brain regional specificity\",\"RNA mouse brain regional distribution\",\"RNA mouse brain regional specificity score\",\"RNA mouse brain regional specific nTPM\",\"RNA pig brain regional specificity\",\"RNA pig brain regional distribution\",\"RNA pig brain regional specificity score\",\"RNA pig brain regional specific nTPM\",Antibody,\"Reliability (IH)\",\"Reliability (Mouse Brain)\",\"Reliability (IF)\",\"Subcellular location\",\"Secretome location\",\"Secretome function\",\"CCD Protein\",\"CCD Transcript\",\"Blood concentration - Conc. blood IM [pg/L]\",\"Blood concentration - Conc. blood MS [pg/L]\",\"Blood expression cluster\",\"Tissue expression cluster\",\"Brain expression cluster\",\"Cell line expression cluster\",\"Single cell expression cluster\",Interactions,\"Subcellular main location\",\"Subcellular additional location\",\"Antibody RRID\",\"Pathology prognostics - Breast cancer\",\"Pathology prognostics - Cervical cancer\",\"Pathology prognostics - Colorectal cancer\",\"Pathology prognostics - Endometrial cancer\",\"Pathology prognostics - Glioma\",\"Pathology prognostics - Head and neck cancer\",\"Pathology prognostics - Liver cancer\",\"Pathology prognostics - Lung cancer\",\"Pathology prognostics - Melanoma\",\"Pathology prognostics - Ovarian cancer\",\"Pathology prognostics - Pancreatic cancer\",\"Pathology prognostics - Prostate cancer\",\"Pathology prognostics - Renal cancer\",\"Pathology prognostics - Stomach cancer\",\"Pathology prognostics - Testis cancer\",\"Pathology prognostics - Thyroid cancer\",\"Pathology prognostics - Urothelial cancer\"\n",
      "TSPAN6,\"T245, TM4SF6, TSPAN-6\",ENSG00000000003,\"Tetraspanin 6\",O43657,X,100627108-100639991,\"Predicted intracellular proteins, Predicted membrane proteins\",,,,\"Evidence at protein level\",\"Evidence at transcript level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Low tissue specificity\",\"Detected in many\",,,\"Cell type enriched\",\"Detected in many\",6,\"Late spermatids: 1752.2\",\"Low cancer specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,\"Immune cell enhanced\",\"Detected in some\",,\"naive CD4 T-cell: 2.1\",\"Lineage enriched\",\"Detected in single\",7,\"T-cells: 2.1\",\"Low cancer specificity\",\"Detected in many\",,,\"Liver - Hepatocytes, Testis - Late spermatids, Thyroid - Thyroid glandular cells\",\"Low region specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,HPA004109,Approved,,Approved,\"Nucleoli fibrillar center,Cell Junctions,Cytosol\",,,NA,NA,,,\"Cluster 43: Non-specific - Transcription & Translation\",\"Cluster 8: Ciliated cells - Cilium organization\",\"Cluster 3: Choroid plexus - Cilium\",\"Cluster 53: Squamous epithelial cells - Keratinization\",\"Cluster 36: Late spermatids - Unknown function\",,\"Cell Junctions, Cytosol\",\"Nucleoli fibrillar center\",\"HPA004109: AB_1080301\",\"unprognostic (7.71e-2)\",\"unprognostic (8.97e-2)\",\"unprognostic (3.56e-2)\",\"unprognostic (2.57e-1)\",\"unprognostic (2.71e-3)\",\"unprognostic (5.93e-2)\",\"unprognostic (1.04e-1)\",\"unprognostic (1.09e-2)\",\"unprognostic (1.19e-2)\",\"unprognostic (1.80e-3)\",\"unprognostic (2.04e-3)\",\"unprognostic (8.76e-2)\",\"unprognostic (3.83e-3)\",\"unprognostic (4.28e-2)\",\"unprognostic (1.14e-1)\",\"unprognostic (2.24e-1)\",\"unprognostic (9.54e-3)\"\n",
      "TNMD,\"BRICD4, ChM1L, myodulin, TEM, tendin\",ENSG00000000005,Tenomodulin,Q9H2S6,X,100584936-100599885,\"Predicted membrane proteins\",,,,\"Evidence at protein level\",\"Evidence at transcript level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Tissue enhanced\",\"Detected in some\",,\"adipose tissue: 20.4;breast: 12.5;seminal vesicle: 25.2\",\"Cell type enriched\",\"Detected in some\",6,\"Adipocytes: 72.2\",\"Low cancer specificity\",\"Detected in some\",,,\"Low region specificity\",\"Detected in some\",,,\"Not detected in immune cells\",\"Not detected\",,,\"Not detected\",\"Not detected\",,,\"Group enriched\",\"Detected in some\",5,\"testis cancer: 1.1;Uterine cancer: 1.3\",\"Skeletal muscle - Fibroblasts\",\"Low region specificity\",\"Detected in many\",,,\"Low region specificity\",\"Detected in many\",,,\"HPA034961, HPA055634\",Uncertain,,,,,,NA,NA,,,,\"Cluster 7: Adipose tissue - Mixed function\",\"Cluster 36: Choroid plexus - Mixed function\",\"Cluster 34: Testis cancer - Unknown function\",\"Cluster 41: Adipocytes & Endothelial cells - Mixed function\",1,,,\"HPA034961: AB_10670285, HPA055634: AB_2682868\",\"unprognostic (3.60e-2)\",,\"unprognostic (9.84e-3)\",\"unprognostic (3.19e-2)\",\"unprognostic (7.77e-3)\",,\"unprognostic (2.42e-1)\",,,\"unprognostic (2.15e-1)\",\"unprognostic (2.36e-2)\",\"unprognostic (1.37e-1)\",\"unprognostic (9.40e-2)\",\"unprognostic (9.60e-4)\",\"unprognostic (6.82e-2)\",\"unprognostic (5.67e-2)\",\"unprognostic (1.48e-1)\"\n",
      "DPM1,\"CDGIE, MPDS\",ENSG00000000419,\"Dolichyl-phosphate mannosyltransferase subunit 1, catalytic\",O60762,20,50934867-50959140,\"Disease related genes, Enzymes, Human disease related genes, Metabolic proteins, Plasma proteins, Potential drug targets, Predicted intracellular proteins\",,\"Glycosyltransferase, Transferase\",\"Congenital disorder of glycosylation, Congenital muscular dystrophy, Disease variant, Dystroglycanopathy\",\"Evidence at protein level\",\"Evidence at transcript level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Low tissue specificity\",\"Detected in all\",,,\"Cell type enhanced\",\"Detected in all\",,\"Basal respiratory cells: 234.7;Syncytiotrophoblasts: 265.5\",\"Low cancer specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,\"Low immune cell specificity\",\"Detected in all\",,,\"Low lineage specificity\",\"Detected in all\",,,\"Low cancer specificity\",\"Detected in all\",,,,\"Low region specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,HPA051818,Approved,,,,,,NA,NA,,,\"Cluster 33: Non-specific - ATP binding\",\"Cluster 35: Non-specific - Mitochondria\",\"Cluster 21: Non-specific - Metabolism\",\"Cluster 62: Non-specific - Plasma proteins\",\"Cluster 35: Respiratory epithelial cells - Unknown function\",3,,,\"HPA051818: AB_2681624\",\"unprognostic (2.21e-2)\",\"unprognostic (4.94e-2)\",\"unprognostic (1.16e-1)\",\"unprognostic (4.24e-3)\",\"unprognostic (1.65e-1)\",\"unprognostic (3.27e-2)\",\"prognostic unfavorable (1.94e-6)\",\"unprognostic (1.10e-1)\",\"unprognostic (7.49e-2)\",\"unprognostic (2.53e-2)\",\"unprognostic (1.29e-2)\",\"unprognostic (3.61e-2)\",\"unprognostic (3.02e-3)\",\"unprognostic (4.98e-2)\",\"unprognostic (2.59e-1)\",\"unprognostic (3.58e-1)\",\"unprognostic (2.74e-1)\"\n",
      "SCYL3,\"PACE-1, PACE1\",ENSG00000000457,\"SCY1 like pseudokinase 3\",Q8IZE3,1,169849631-169894267,\"Enzymes, Predicted intracellular proteins\",,,,\"Evidence at protein level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Low tissue specificity\",\"Detected in all\",,,\"Low cell type specificity\",\"Detected in many\",,,\"Low cancer specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,\"Low immune cell specificity\",\"Detected in all\",,,\"Low lineage specificity\",\"Detected in all\",,,\"Low cancer specificity\",\"Detected in all\",,,\"Liver - Hepatocytes\",\"Low region specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,\"HPA005624, HPA072383\",Approved,,Supported,\"Golgi apparatus,Cytosol\",,,NA,NA,,,\"Cluster 5: Non-specific - Cell proliferation\",\"Cluster 1: Liver & Kidney - Metabolism\",\"Cluster 50: Non-specific - Nucleic acid binding\",\"Cluster 45: Non-specific - Nuclear processes\",\"Cluster 55: Non-specific - Transcription\",4,\"Golgi apparatus, Cytosol\",,\"HPA005624: AB_1854916, HPA072383: \",\"unprognostic (2.35e-1)\",\"unprognostic (1.25e-1)\",\"unprognostic (7.53e-2)\",\"unprognostic (8.36e-2)\",\"unprognostic (7.13e-2)\",\"unprognostic (2.72e-3)\",\"unprognostic (1.31e-1)\",\"unprognostic (2.12e-2)\",\"unprognostic (2.85e-2)\",\"unprognostic (7.17e-2)\",\"unprognostic (8.80e-2)\",\"unprognostic (9.88e-2)\",\"unprognostic (1.20e-3)\",\"unprognostic (3.54e-1)\",\"unprognostic (1.75e-1)\",\"unprognostic (4.60e-2)\",\"prognostic favorable (8.85e-4)\"\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Function to unzip a file\n",
    "def unzip_file(zip_file_path, output_folder_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_folder_path)\n",
    "        print(f\"Unzipped files to {output_folder_path}\")\n",
    "\n",
    "# Unzip the file\n",
    "unzip_file('downloaded_hpa_files/proteinatlas.tsv.zip', 'unzipped_folder')\n",
    "\n",
    "# Read the first 5 lines of the unzipped .tsv file\n",
    "try:\n",
    "    with open('unzipped_folder/proteinatlas.tsv', 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 5:\n",
    "                break\n",
    "            print(line.strip().replace('\\t', ','))\n",
    "except FileNotFoundError:\n",
    "    print(\"The file 'proteinatlas.tsv' was not found in the 'unzipped_folder'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as ontology/uHAF_marker_reference.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_file_from_github(url, save_path, folder_name=\"ontology\"):\n",
    "    # Create folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Define the full path to save the file\n",
    "    full_save_path = os.path.join(folder_name, save_path)\n",
    "\n",
    "    # Download the file\n",
    "    response = requests.get(url)\n",
    "    with open(full_save_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(f\"File downloaded and saved as {full_save_path}\")\n",
    "\n",
    "# URL to the hECA marker gene annotation file\n",
    "heca_url = \"https://github.com/XuegongLab/hECA/raw/main/UHAF/uHAF%20marker%20reference.xlsx\"\n",
    "\n",
    "# Name of the file to save\n",
    "heca_save_path = \"uHAF_marker_reference.xlsx\"\n",
    "\n",
    "# Download the file\n",
    "download_file_from_github(heca_url, heca_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPA tissue to marker JSON saved at: ontology/json_output/HPA_tissue_to_marker.json\n",
      "HPA cell_type to marker JSON saved at: ontology/json_output/HPA_cell_type_to_marker.json\n",
      "hECA tissue to marker JSON saved at: ontology/json_output/hECA_tissue_to_marker.json\n",
      "hECA cell_type to marker JSON saved at: ontology/json_output/hECA_cell_type_to_marker.json\n"
     ]
    }
   ],
   "source": [
    "def convert_to_json(file_path, output_directory, is_hpa):\n",
    "    # Create dictionaries for tissues/organs and cell types to markers\n",
    "    tissue_to_marker = defaultdict(set)\n",
    "    cell_type_to_marker = defaultdict(set)\n",
    "\n",
    "    if is_hpa:\n",
    "        # Read the HPA Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Iterate through the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            tissue = row['Tissue']  # 'Tissue' column used for HPA\n",
    "            cell_type = row['Cell type']\n",
    "            marker = row['Marker']\n",
    "            \n",
    "            tissue_to_marker[tissue.strip()].add(marker.strip())\n",
    "            cell_type_to_marker[cell_type.strip()].add(marker.strip())\n",
    "    else:\n",
    "        # Read the hECA Excel file\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "\n",
    "        # Iterate over each sheet\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            df = pd.read_excel(xls, sheet_name)\n",
    "\n",
    "            # Check for 'Marker' or 'marker' column\n",
    "            marker_column = 'Marker' if 'Marker' in df.columns else 'marker'\n",
    "            if marker_column not in df.columns:\n",
    "                raise KeyError(f\"Column 'Marker' or 'marker' not found in sheet {sheet_name}\")\n",
    "\n",
    "            # Iterate through the DataFrame\n",
    "            for index, row in df.iterrows():\n",
    "                tissue = sheet_name  # Use the sheet name as the tissue/organ for hECA\n",
    "                cell_type = row['cell_type']\n",
    "                if pd.isnull(cell_type):\n",
    "                    continue  # Skip rows where cell type is NaN or None\n",
    "            cell_type = str(cell_type).strip()  # Convert to string and strip whitespace\n",
    "        \n",
    "            markers = set(map(str.strip, str(row[marker_column]).split(',')))  # Convert to string and split\n",
    "\n",
    "            tissue_to_marker[tissue.strip()].update(markers)\n",
    "            cell_type_to_marker[cell_type].update(markers)\n",
    "\n",
    "    # Save to JSON files\n",
    "    for category, cat_to_marker in [('tissue', tissue_to_marker), ('cell_type', cell_type_to_marker)]:\n",
    "        json_file_path = os.path.join(output_directory, f\"{'HPA' if is_hpa else 'hECA'}_{category}_to_marker.json\")\n",
    "        with open(json_file_path, 'w') as json_file:\n",
    "            json.dump({k: list(v) for k, v in cat_to_marker.items()}, json_file, indent=4)\n",
    "        print(f\"{'HPA' if is_hpa else 'hECA'} {category} to marker JSON saved at: {json_file_path}\")\n",
    "\n",
    "# Correct file paths before running the function\n",
    "hpa_excel_file_path = 'ontology/HPA_marker_reference.xlsx'\n",
    "heca_excel_file_path = 'ontology/uHAF_marker_reference.xlsx'\n",
    "output_directory = 'ontology/json_output'\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Convert and save the HPA Excel file to JSON\n",
    "convert_to_json(hpa_excel_file_path, output_directory, is_hpa=True)\n",
    "\n",
    "# Convert and save the hECA Excel file to JSON\n",
    "convert_to_json(heca_excel_file_path, output_directory, is_hpa=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'basal cell', 'keratinocyte', 'b cell', 'exocrine cell', 'melanocyte', 'proximal convoluted tubule', 'sertoli cell', 'rod cell', 'horizontal cell', 'ductal cell', 'paneth cell', 't cell', 'granulocyte', 'muller cell', 'goblet cell', 'endothelial cell', 'enterocyte', 'endocrine cell', 'dendritic cell', 'distal convoluted tubule', 'fibroblast', 'erythroid cell', 'macrophage', 'smooth muscle cell', 'club cell/bronchiolar exocrine cell/clara cell', 'cardiomyocyte cell', 'cone cell', 'monocyte', 'collecting duct', 'hepatocyte'}\n",
      "\n",
      "\n",
      "basal cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "keratinocyte: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "b cell: {'common_markers': 2, 'percentage_common_markers_heca': 25.0, 'percentage_common_markers_hpa': 66.7}\n",
      "exocrine cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "melanocyte: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "proximal convoluted tubule: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "sertoli cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "rod cell: {'common_markers': 2, 'percentage_common_markers_heca': 50.0, 'percentage_common_markers_hpa': 66.7}\n",
      "horizontal cell: {'common_markers': 3, 'percentage_common_markers_heca': 100.0, 'percentage_common_markers_hpa': 100.0}\n",
      "ductal cell: {'common_markers': 1, 'percentage_common_markers_heca': 25.0, 'percentage_common_markers_hpa': 33.3}\n",
      "paneth cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "t cell: {'common_markers': 1, 'percentage_common_markers_heca': 2.8, 'percentage_common_markers_hpa': 33.3}\n",
      "granulocyte: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "muller cell: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "goblet cell: {'common_markers': 2, 'percentage_common_markers_heca': 14.3, 'percentage_common_markers_hpa': 66.7}\n",
      "endothelial cell: {'common_markers': 4, 'percentage_common_markers_heca': 10.8, 'percentage_common_markers_hpa': 100.0}\n",
      "enterocyte: {'common_markers': 2, 'percentage_common_markers_heca': 10.0, 'percentage_common_markers_hpa': 25.0}\n",
      "endocrine cell: {'common_markers': 1, 'percentage_common_markers_heca': 33.3, 'percentage_common_markers_hpa': 33.3}\n",
      "dendritic cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "distal convoluted tubule: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "fibroblast: {'common_markers': 2, 'percentage_common_markers_heca': 7.4, 'percentage_common_markers_hpa': 66.7}\n",
      "erythroid cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "macrophage: {'common_markers': 2, 'percentage_common_markers_heca': 6.9, 'percentage_common_markers_hpa': 40.0}\n",
      "smooth muscle cell: {'common_markers': 2, 'percentage_common_markers_heca': 10.0, 'percentage_common_markers_hpa': 66.7}\n",
      "club cell/bronchiolar exocrine cell/clara cell: {'common_markers': 2, 'percentage_common_markers_heca': 22.2, 'percentage_common_markers_hpa': 66.7}\n",
      "cardiomyocyte cell: {'common_markers': 3, 'percentage_common_markers_heca': 42.9, 'percentage_common_markers_hpa': 75.0}\n",
      "cone cell: {'common_markers': 2, 'percentage_common_markers_heca': 28.6, 'percentage_common_markers_hpa': 66.7}\n",
      "monocyte: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "collecting duct: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "hepatocyte: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def create_custom_mapping():\n",
    "    \"\"\"\n",
    "    Create a custom mapping from plural forms (common in HPA) to singular forms (common in hECA).\n",
    "    This helps in aligning cell types between the two datasets.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'b cells': 'b cell',\n",
    "        'dendritic cells': 'dendritic cell',\n",
    "        'endothelial cells': 'endothelial cell',\n",
    "        'fibroblasts': 'fibroblast',\n",
    "        'granulocytes': 'granulocyte',\n",
    "        'macrophages': 'macrophage',\n",
    "        'monocytes': 'monocyte',\n",
    "        'smooth muscle cells': 'smooth muscle cell',\n",
    "        't cells': 't cell',\n",
    "        'enterocytes': 'enterocyte',\n",
    "        'goblet cells': 'goblet cell',\n",
    "        'paneth cells': 'paneth cell',\n",
    "        'enterocytes': 'enterocyte',\n",
    "        'cone photoreceptor cells': 'cone cell',\n",
    "        'horizontal cells': 'horizontal cell',\n",
    "        'muller glia cells': 'muller cell',\n",
    "        'rod photoreceptor cells': 'rod cell',\n",
    "        'cardiomyocytes': 'cardiomyocyte cell',\n",
    "        'collecting duct cells': 'collecting duct',\n",
    "        'distal tubular cells': 'distal convoluted tubule',\n",
    "        'proximal tubular cells': 'proximal convoluted tubule',\n",
    "        'erythroid cells': 'erythroid cell',\n",
    "        'hepatocytes': 'hepatocyte',\n",
    "        'kupffer cells': 'kupffer cell',\n",
    "        'bronchial epithelium, club cells': 'club cell/bronchiolar exocrine cell/clara cell',\n",
    "        'alveolar cells type 1': 'type I alveolar cell/type I pneumocyte',\n",
    "        'alveolar cells type 2': 'type II alveolar cell/type II pneumocyte',\n",
    "        'exocrine glandular cells': 'exocrine cell',\n",
    "        'ductal cells': 'ductal cell',\n",
    "        'pancreatic endocrine cells': 'endocrine cell',\n",
    "        'exocrine glandular cells': 'exocrine cell',\n",
    "        'basal glandular cells': 'basal cell',\n",
    "        'suprabasal keratinocytes': 'keratinocyte',\n",
    "        'melanocytes': 'melanocyte',\n",
    "        'paneth cells ': 'paneth cell',\n",
    "        'sertoli cells': 'sertoli cell',\n",
    "        'spermatogonia ': 'differentiating spermatogonia',\n",
    "        'spermatogonia ': 'differentiated spermatogonia',\n",
    "        # Add more mappings as needed based on the cell types in your datasets\n",
    "    }\n",
    "\n",
    "def normalize_name(name, custom_mapping):\n",
    "    \"\"\"\n",
    "    Normalize cell type names by applying custom mappings for known discrepancies.\n",
    "    \"\"\"\n",
    "    normalized = name.strip().lower().replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "    # Convert plural to singular by checking custom mapping\n",
    "    normalized = custom_mapping.get(normalized, normalized)\n",
    "    return normalized\n",
    "\n",
    "def load_and_normalize_data(file_path, custom_mapping):\n",
    "    \"\"\"\n",
    "    Load JSON data from a file, normalize cell type names using the custom mapping,\n",
    "    and return a dictionary with normalized cell type names as keys.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Normalize cell type names and return a new dictionary\n",
    "    return {normalize_name(key, custom_mapping): set(value) for key, value in data.items()}\n",
    "\n",
    "# Define your custom mapping\n",
    "custom_mapping = create_custom_mapping()\n",
    "\n",
    "# Load and normalize the data from JSON files\n",
    "heca_cell_type_to_marker = load_and_normalize_data('ontology/json_output/hECA_cell_type_to_marker.json', custom_mapping)\n",
    "hpa_cell_type_to_marker = load_and_normalize_data('ontology/json_output/HPA_cell_type_to_marker.json', custom_mapping)\n",
    "\n",
    "common_cell_types = set(heca_cell_type_to_marker.keys()) & set(hpa_cell_type_to_marker.keys())\n",
    "print(common_cell_types)\n",
    "print('\\n')\n",
    "\n",
    "similarity_stats = {}\n",
    "\n",
    "for cell_type in common_cell_types:\n",
    "    heca_markers = heca_cell_type_to_marker[cell_type]\n",
    "    hpa_markers = hpa_cell_type_to_marker[cell_type]\n",
    "    common_markers = heca_markers & hpa_markers\n",
    "    \n",
    "    total_markers_heca = len(heca_markers)\n",
    "    total_markers_hpa = len(hpa_markers)\n",
    "    total_common_markers = len(common_markers)\n",
    "    \n",
    "    similarity_stats[cell_type] = {\n",
    "        \"common_markers\": total_common_markers,\n",
    "        \"percentage_common_markers_heca\": round((total_common_markers / total_markers_heca) * 100, 1) if total_markers_heca else 0,\n",
    "        \"percentage_common_markers_hpa\": round((total_common_markers / total_markers_hpa) * 100, 1) if total_markers_hpa else 0,\n",
    "    }\n",
    "\n",
    "# Display the similarity statistics\n",
    "for cell_type, stats in similarity_stats.items():\n",
    "    print(f\"{cell_type}: {stats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rod cell', 'club cell/bronchiolar exocrine cell/clara cell', 'keratinocyte', 'collecting duct', 'horizontal cell', 'goblet cell', 'fibroblast', 'exocrine cell', 'urothelial cell', 'proximal convoluted tubule', 'muller cell', 'paneth cell', 'ductal cell', 'sertoli cell', 'erythroid cell', 't cell', 'smooth muscle cell', 'basal cell', 'b cell', 'cardiomyocyte cell', 'dendritic cell', 'distal convoluted tubule', 'endothelial cell', 'cone cell'}\n",
      "\n",
      "\n",
      "rod cell: {'common_markers': 2, 'percentage_common_markers_heca': 50.0, 'percentage_common_markers_hpa': 66.7}\n",
      "club cell/bronchiolar exocrine cell/clara cell: {'common_markers': 2, 'percentage_common_markers_heca': 22.2, 'percentage_common_markers_hpa': 66.7}\n",
      "keratinocyte: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "horizontal cell: {'common_markers': 3, 'percentage_common_markers_heca': 100.0, 'percentage_common_markers_hpa': 100.0}\n",
      "goblet cell: {'common_markers': 2, 'percentage_common_markers_heca': 14.3, 'percentage_common_markers_hpa': 66.7}\n",
      "fibroblast: {'common_markers': 2, 'percentage_common_markers_heca': 7.4, 'percentage_common_markers_hpa': 66.7}\n",
      "muller cell: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "ductal cell: {'common_markers': 1, 'percentage_common_markers_heca': 25.0, 'percentage_common_markers_hpa': 33.3}\n",
      "t cell: {'common_markers': 1, 'percentage_common_markers_heca': 2.8, 'percentage_common_markers_hpa': 33.3}\n",
      "smooth muscle cell: {'common_markers': 2, 'percentage_common_markers_heca': 10.0, 'percentage_common_markers_hpa': 66.7}\n",
      "b cell: {'common_markers': 2, 'percentage_common_markers_heca': 25.0, 'percentage_common_markers_hpa': 66.7}\n",
      "cardiomyocyte cell: {'common_markers': 3, 'percentage_common_markers_heca': 42.9, 'percentage_common_markers_hpa': 75.0}\n",
      "endothelial cell: {'common_markers': 4, 'percentage_common_markers_heca': 10.8, 'percentage_common_markers_hpa': 100.0}\n",
      "cone cell: {'common_markers': 2, 'percentage_common_markers_heca': 28.6, 'percentage_common_markers_hpa': 66.7}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def create_custom_mapping():\n",
    "    \"\"\"\n",
    "    Define a mapping for cell type synonyms and specific exceptions.\n",
    "    This function now focuses on special cases not handled by automatic pluralization and normalization.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        # Explicit mappings for cases with missing words or different word ending\n",
    "        'bronchial epithelium, club cells': 'club cell/bronchiolar exocrine cell/clara cell',\n",
    "        'alveolar cells type 1': 'type I alveolar cell/type I pneumocyte',\n",
    "        'alveolar cells type 2': 'type II alveolar cell/type II pneumocyte',\n",
    "        'cone photoreceptor cells': 'cone cell',\n",
    "        'muller glia cells': 'muller cell',\n",
    "        'rod photoreceptor cells': 'rod cell',\n",
    "        'cardiomyocytes': 'cardiomyocyte cell',\n",
    "        'collecting duct cells': 'collecting duct',\n",
    "        'distal tubular cells': 'distal convoluted tubule',\n",
    "        'proximal tubular cells': 'proximal convoluted tubule',\n",
    "        'exocrine glandular cells': 'exocrine cell',\n",
    "        'basal glandular cells': 'basal cell',\n",
    "        'suprabasal keratinocytes': 'keratinocyte',\n",
    "        'spermatogonia ': 'differentiating spermatogonia',\n",
    "        'spermatogonia ': 'differentiated spermatogonia',\n",
    "        # Add or adjust mappings as needed for specific cases\n",
    "    }\n",
    "\n",
    "def normalize_name(name, custom_mapping):\n",
    "    \"\"\"\n",
    "    Normalize cell type names by applying custom mappings for known discrepancies, \n",
    "    including automatic adjustments for case, hyphens, underscores, \n",
    "    and handling singular/plural forms relevant to cell types.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and replace hyphens/underscores with spaces\n",
    "    normalized = name.strip().lower().replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "\n",
    "    # Apply custom mappings first for specific synonyms and exceptions\n",
    "    normalized = custom_mapping.get(normalized, normalized)\n",
    "\n",
    "    # Automatically handle plural forms with basic English rules, tailored for cell types\n",
    "    if normalized.endswith('ies'):\n",
    "        normalized = re.sub('ies$', 'y', normalized)  # Correct rule for converting plurals ending in 'ies' to 'y'\n",
    "    elif normalized.endswith('es'):\n",
    "        # Correct handling for plurals ending in 'es', which might be common for certain biological terms\n",
    "        normalized = normalized[:-2]  # Removes the 'es', e.g., \"paneth cells\" to \"paneth cell\"\n",
    "    elif normalized.endswith('s') and not normalized.endswith('ss'):\n",
    "        normalized = normalized[:-1]  # General case for plurals not ending in 'ss', e.g., \"cells\" to \"cell\"\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def load_and_normalize_data(file_path, custom_mapping):\n",
    "    \"\"\"\n",
    "    Load JSON data from a file, normalize cell type names using the custom mapping,\n",
    "    and return a dictionary with normalized cell type names as keys.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Normalize cell type names and return a new dictionary\n",
    "    return {normalize_name(key, custom_mapping): set(value) for key, value in data.items()}\n",
    "\n",
    "# Define your custom mapping\n",
    "custom_mapping = create_custom_mapping()\n",
    "\n",
    "# Load and normalize the data from JSON files\n",
    "heca_cell_type_to_marker = load_and_normalize_data('ontology/json_output/hECA_cell_type_to_marker.json', custom_mapping)\n",
    "hpa_cell_type_to_marker = load_and_normalize_data('ontology/json_output/HPA_cell_type_to_marker.json', custom_mapping)\n",
    "\n",
    "common_cell_types = set(heca_cell_type_to_marker.keys()) & set(hpa_cell_type_to_marker.keys())\n",
    "print(common_cell_types)\n",
    "print('\\n')\n",
    "\n",
    "similarity_stats = {}\n",
    "\n",
    "for cell_type in common_cell_types:\n",
    "    heca_markers = heca_cell_type_to_marker[cell_type]\n",
    "    hpa_markers = hpa_cell_type_to_marker[cell_type]\n",
    "    common_markers = heca_markers & hpa_markers\n",
    "    \n",
    "    total_markers_heca = len(heca_markers)\n",
    "    total_markers_hpa = len(hpa_markers)\n",
    "    total_common_markers = len(common_markers)\n",
    "    \n",
    "    # Only add to similarity_stats if total_common_markers is greater than 0\n",
    "    if total_common_markers > 0:\n",
    "        similarity_stats[cell_type] = {\n",
    "            \"common_markers\": total_common_markers,\n",
    "            \"percentage_common_markers_heca\": round((total_common_markers / total_markers_heca) * 100, 1) if total_markers_heca else 0,\n",
    "            \"percentage_common_markers_hpa\": round((total_common_markers / total_markers_hpa) * 100, 1) if total_markers_hpa else 0,\n",
    "        }\n",
    "\n",
    "for cell_type, stats in similarity_stats.items():\n",
    "    print(f\"{cell_type}: {stats}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Data written to output_files/cell_types_to_ensembl.json\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "class GeneExpressionAtlas:\n",
    "    def __init__(self, data_path, columns_to_check):\n",
    "        self.data_path = data_path\n",
    "        self.columns_to_check = columns_to_check\n",
    "        self.cell_types_to_ensembl = defaultdict(set)\n",
    "\n",
    "    def extract_cell_types(self):\n",
    "        df = pd.read_csv(self.data_path, sep='\\t')\n",
    "        for index, row in df.iterrows():\n",
    "            ensembl_id = row['Ensembl']\n",
    "            for col in self.columns_to_check:\n",
    "                cell_type_data = row[col]\n",
    "                if pd.notna(cell_type_data):\n",
    "                    for item in cell_type_data.split(';'):\n",
    "                        cell_type = item.split(':')[0].strip()\n",
    "                        self.cell_types_to_ensembl[cell_type].add(ensembl_id)\n",
    "        return self.cell_types_to_ensembl\n",
    "\n",
    "    def to_json(self, output_path):\n",
    "        # Convert sets to lists for JSON serialization\n",
    "        for cell_type, ensembl_ids in self.cell_types_to_ensembl.items():\n",
    "            self.cell_types_to_ensembl[cell_type] = list(ensembl_ids)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(self.cell_types_to_ensembl, f)\n",
    "        return output_path\n",
    "\n",
    "class HPA(GeneExpressionAtlas):\n",
    "    def __init__(self, data_path):\n",
    "        columns_to_check = [\n",
    "            \"RNA tissue specific nTPM\",\n",
    "            \"RNA single cell type specific nTPM\",\n",
    "            \"RNA blood cell specific nTPM\",\n",
    "            \"RNA blood lineage specific nTPM\"\n",
    "        ]\n",
    "        super().__init__(data_path, columns_to_check)\n",
    "\n",
    "class hECA(GeneExpressionAtlas):\n",
    "    # hECA specific implementation would go here, if needed.\n",
    "    pass\n",
    "\n",
    "# Example usage for HPA\n",
    "hpa_data_path = \"unzipped_folder/proteinatlas.tsv\"\n",
    "hpa = HPA(hpa_data_path)\n",
    "\n",
    "# Extract cell types and associated Ensembl Gene IDs\n",
    "hpa_cell_types_to_ensembl = hpa.extract_cell_types()\n",
    "\n",
    "# Directory where the aggregated results will be saved\n",
    "output_directory = \"output_files\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Write the results to a JSON file\n",
    "json_file_path = hpa.to_json(f'{output_directory}/cell_types_to_ensembl.json')\n",
    "print(f\"Data written to {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'\\n%pip install pandas\\nimport pandas as pd\\n\\nclass GeneExpressionAtlas:\\n    def __init__(self, data_path, columns_to_check, custom_mapping=None):\\n        self.data_path = data_path\\n        self.columns_to_check = columns_to_check\\n        self.custom_mapping = custom_mapping if custom_mapping else create_custom_mapping()\\n        self.cell_types_to_ensembl = defaultdict(set)\\n\\n    def extract_cell_types(self):\\n        df = pd.read_csv(self.data_path, sep=\\'\\t\\')\\n        for _, row in df.iterrows():\\n            ensembl_id = row[\\'Ensembl\\']\\n            for col in self.columns_to_check:\\n                cell_type_data = row[col]\\n                if pd.notna(cell_type_data):\\n                    for item in cell_type_data.split(\\';\\'):\\n                        cell_type, _ = item.split(\\':\\')  # Assume format is \"cell_type:expression\"\\n                        normalized_cell_type = normalize_name(cell_type, self.custom_mapping)\\n                        self.cell_types_to_ensembl[normalized_cell_type].add(ensembl_id)\\n        return self.cell_types_to_ensembl\\n\\nintersection = {}\\nfor cell_type in hpa_cell_types_to_ensembl:\\n    if cell_type in heca_cell_type_to_marker:\\n        intersection[cell_type] = {\\n            \\'HPA_Ensembl_IDs\\': list(hpa_cell_types_to_ensembl[cell_type]),\\n            \\'hECA_markers\\': heca_cell_type_to_marker[cell_type]\\n        }\\n\\n# Print the intersection\\nfor cell_type, data in intersection.items():\\n    print(f\"Cell Type: {cell_type}\")\\n    print(f\"HPA Ensembl Gene IDs: {data[\\'HPA_Ensembl_IDs\\']}\")\\n    print(f\"hECA Marker Genes: {data[\\'hECA_markers\\']}\\n\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "class GeneExpressionAtlas:\n",
    "    def __init__(self, data_path, columns_to_check, custom_mapping=None):\n",
    "        self.data_path = data_path\n",
    "        self.columns_to_check = columns_to_check\n",
    "        self.custom_mapping = custom_mapping if custom_mapping else create_custom_mapping()\n",
    "        self.cell_types_to_ensembl = defaultdict(set)\n",
    "\n",
    "    def extract_cell_types(self):\n",
    "        df = pd.read_csv(self.data_path, sep='\\t')\n",
    "        for _, row in df.iterrows():\n",
    "            ensembl_id = row['Ensembl']\n",
    "            for col in self.columns_to_check:\n",
    "                cell_type_data = row[col]\n",
    "                if pd.notna(cell_type_data):\n",
    "                    for item in cell_type_data.split(';'):\n",
    "                        cell_type, _ = item.split(':')  # Assume format is \"cell_type:expression\"\n",
    "                        normalized_cell_type = normalize_name(cell_type, self.custom_mapping)\n",
    "                        self.cell_types_to_ensembl[normalized_cell_type].add(ensembl_id)\n",
    "        return self.cell_types_to_ensembl\n",
    "\n",
    "intersection = {}\n",
    "for cell_type in hpa_cell_types_to_ensembl:\n",
    "    if cell_type in heca_cell_type_to_marker:\n",
    "        intersection[cell_type] = {\n",
    "            'HPA_Ensembl_IDs': list(hpa_cell_types_to_ensembl[cell_type]),\n",
    "            'hECA_markers': heca_cell_type_to_marker[cell_type]\n",
    "        }\n",
    "\n",
    "# Print the intersection\n",
    "for cell_type, data in intersection.items():\n",
    "    print(f\"Cell Type: {cell_type}\")\n",
    "    print(f\"HPA Ensembl Gene IDs: {data['HPA_Ensembl_IDs']}\")\n",
    "    print(f\"hECA Marker Genes: {data['hECA_markers']}\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: goatools in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (1.3.11)\n",
      "Requirement already satisfied: networkx in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (3.2.1)\n",
      "Requirement already satisfied: scipy in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: statsmodels in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (0.14.1)\n",
      "Requirement already satisfied: mygene in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (3.2.2)\n",
      "Requirement already satisfied: matplotlib in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (3.8.3)\n",
      "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (2.31.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: xlsxwriter in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (3.1.9)\n",
      "Requirement already satisfied: openpyxl in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (3.1.2)\n",
      "Requirement already satisfied: docopt in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (0.6.2)\n",
      "Requirement already satisfied: pydot in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (2.0.0)\n",
      "Requirement already satisfied: rich in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (13.7.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from mygene) (0.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: et-xmlfile in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from openpyxl->goatools) (1.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from rich->goatools) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from rich->goatools) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->goatools) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "COULD NOT READ(ontology/go-basic.obo)\ndownload obo file first\n [http://geneontology.org/ontology/go-basic.obo]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 119\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m# Example usage - paths need to be specified for your GO OBO file and gene2go association file\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03mgene_expression_atlas = GeneExpressionAtlas(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Instantiate the class\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m gene_expression_atlas \u001b[38;5;241m=\u001b[39m \u001b[43mGeneExpressionAtlas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath/to/proteinatlas.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcolumns_to_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumn2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgo_obo_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43montology/go-basic.obo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgene2go_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43montology/gene2go\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m gene_expression_atlas\u001b[38;5;241m.\u001b[39mdownload_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://purl.obolibrary.org/obo/go/go-basic.obo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124montology\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m gene_expression_atlas\u001b[38;5;241m.\u001b[39mdownload_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2go.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124montology\u001b[39m\u001b[38;5;124m\"\u001b[39m, decompress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m, in \u001b[0;36mGeneExpressionAtlas.__init__\u001b[0;34m(self, data_path, columns_to_check, custom_mapping, go_obo_path, gene2go_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgo_obo_path \u001b[38;5;241m=\u001b[39m go_obo_path  \u001b[38;5;66;03m# Path to the GO OBO file\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgene2go_path \u001b[38;5;241m=\u001b[39m gene2go_path  \u001b[38;5;66;03m# Path to the gene2go association file\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgo_dag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m go_obo_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mobo_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGODag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgo_obo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgene2go \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gene2go_path \u001b[38;5;28;01melse\u001b[39;00m read_ncbi_gene2go(gene2go_path, taxids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m9606\u001b[39m])  \u001b[38;5;66;03m# Assuming human genes\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data_path, columns_to_check)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/goatools/obo_parser.py:317\u001b[0m, in \u001b[0;36mGODag.__init__\u001b[0;34m(self, obo_file, optional_attrs, load_obsolete, prt)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    311\u001b[0m     obo_file: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo-basic.obo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m     prt\u001b[38;5;241m=\u001b[39mstdout,\n\u001b[1;32m    315\u001b[0m ):\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28msuper\u001b[39m(GODag, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_obo_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobo_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_obsolete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprt\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/goatools/obo_parser.py:323\u001b[0m, in \u001b[0;36mGODag.load_obo_file\u001b[0;34m(self, obo_file, optional_attrs, load_obsolete, prt)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_obo_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, obo_file, optional_attrs, load_obsolete, prt):\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read obo file. Store results.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mOBOReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobo_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional_attrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;66;03m# Save alt_ids and their corresponding main GO ID. Add to GODag after populating GO Terms\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     alt2rec \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/goatools/obo_parser.py:56\u001b[0m, in \u001b[0;36mOBOReader.__init__\u001b[0;34m(self, obo_file, optional_attrs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobo_file \u001b[38;5;241m=\u001b[39m obo_file\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# GOTerm attributes that are necessary for any operations:\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOULD NOT READ(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobo_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownload obo file first\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[http://geneontology.org/ontology/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo-basic.obo]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: COULD NOT READ(ontology/go-basic.obo)\ndownload obo file first\n [http://geneontology.org/ontology/go-basic.obo]"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "class GeneExpressionAtlas:\n",
    "    def __init__(self, data_path, columns_to_check, custom_mapping=None):\n",
    "        self.data_path = data_path\n",
    "        self.columns_to_check = columns_to_check\n",
    "        self.custom_mapping = custom_mapping if custom_mapping else self.create_custom_mapping()\n",
    "        self.cell_types_to_ensembl = defaultdict(set)\n",
    "        \n",
    "        # Download required files before loading them\n",
    "        self.download_and_prepare_ontology_files()\n",
    "\n",
    "        # Now it's safe to load the GO DAG and gene2go data\n",
    "        if self.go_obo_path:\n",
    "            self.go_dag = GODag(self.go_obo_path)\n",
    "        if self.gene2go_path:\n",
    "            self.gene2go = read_ncbi_gene2go(self.gene2go_path, taxids=[9606])  # Assuming human genes\n",
    "\n",
    "    def create_custom_mapping(self):\n",
    "        # Placeholder for your custom mapping function\n",
    "        return {}\n",
    "\n",
    "    def download_and_prepare_ontology_files(self):\n",
    "        # Specify the ontology folder and file URLs\n",
    "        ontology_folder = \"ontology\"\n",
    "        self.go_obo_path = os.path.join(ontology_folder, \"go-basic.obo\")\n",
    "        self.gene2go_path = os.path.join(ontology_folder, \"gene2go\")\n",
    "        \n",
    "        go_obo_url = \"http://purl.obolibrary.org/obo/go/go-basic.obo\"\n",
    "        gene2go_url = \"ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2go.gz\"\n",
    "\n",
    "        # Download the files\n",
    "        self.download_file(go_obo_url, ontology_folder)\n",
    "        self.download_file(gene2go_url, ontology_folder, decompress=True)\n",
    "\n",
    "    def download_file(self, url, dest_folder, decompress=False):\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)  # Create directory if it does not exist\n",
    "\n",
    "        filename = url.split('/')[-1]\n",
    "        file_path = os.path.join(dest_folder, filename)\n",
    "        \n",
    "        # Download the file\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "            if decompress and filename.endswith('.gz'):\n",
    "                with gzip.open(file_path, 'rb') as f_in:\n",
    "                    with open(file_path[:-3], 'wb') as f_out:  # Remove .gz extension for the output file\n",
    "                        f_out.write(f_in.read())\n",
    "                os.remove(file_path)  # Remove the compressed file\n",
    "                print(f\"Decompressed {filename}\")\n",
    "        else:\n",
    "            print(f\"Error downloading {filename}: Status Code {response.status_code}\")\n",
    "\n",
    "# Further implementation of GeneExpressionAtlas methods...\n",
    "\n",
    "# Example usage:\n",
    "gene_expression_atlas = GeneExpressionAtlas(\n",
    "    data_path=\"path/to/proteinatlas.tsv\",\n",
    "    columns_to_check=[\"column1\", \"column2\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_files/cell_types_for_all_genelists.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Function to load a genelist from a file\n",
    "def load_genelist(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Remove quotes and strip whitespace from each line\n",
    "        return [line.strip().strip('\"') for line in f.read().splitlines()]\n",
    "\n",
    "# Load the cell_types_to_ensembl.json file\n",
    "cell_types_to_ensembl_filepath = 'output_files/cell_types_to_ensembl.json'\n",
    "with open(cell_types_to_ensembl_filepath, 'r') as f:\n",
    "    cell_types_to_ensembl = json.load(f)\n",
    "\n",
    "# Load all genelists using file paths for the gene lists\n",
    "genelists_files = [f'genelists/Genelist{i}.txt' for i in range(1, 7)]\n",
    "\n",
    "# Initialize a dictionary to store cell type frequencies for all genelists\n",
    "cell_types_for_all_genelists = {}\n",
    "\n",
    "# Loop through each genelist file\n",
    "for i, genelist_file in enumerate(genelists_files, 1):\n",
    "    # Load the current genelist\n",
    "    genelist = load_genelist(genelist_file)\n",
    "    \n",
    "    # Initialize a defaultdict to store the results for the current genelist\n",
    "    cell_types_for_genelist = defaultdict(int)\n",
    "\n",
    "    # Identify cell types associated with the genes in the current genelist\n",
    "    for cell_type, ensembl_ids in cell_types_to_ensembl.items():\n",
    "        for ensembl_id in genelist:\n",
    "            if ensembl_id in ensembl_ids:\n",
    "                cell_types_for_genelist[cell_type] += 1\n",
    "\n",
    "    # Store the results for the current genelist\n",
    "    cell_types_for_all_genelists[f'Genelist{i}'] = cell_types_for_genelist\n",
    "\n",
    "# Save the aggregated results to a JSON file\n",
    "cell_types_for_all_genelists_file = 'output_files/cell_types_for_all_genelists.json'\n",
    "with open(cell_types_for_all_genelists_file, 'w') as f:\n",
    "    json.dump(cell_types_for_all_genelists, f)\n",
    "\n",
    "cell_types_for_all_genelists_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ENSG00000000003',\n",
       "  'ENSG00000000005',\n",
       "  'ENSG00000000419',\n",
       "  'ENSG00000000457',\n",
       "  'ENSG00000000460'],\n",
       " 'output_files/protein_atlas_ensembl_ids.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the protein atlas data\n",
    "protein_atlas_filepath = 'unzipped_folder/proteinatlas.tsv'\n",
    "protein_atlas_df = pd.read_csv(protein_atlas_filepath, sep='\\t')\n",
    "\n",
    "# Extract the Ensembl IDs from the 'Gene' column\n",
    "ensembl_ids = protein_atlas_df['Ensembl'].unique().tolist()\n",
    "\n",
    "# Save the Ensembl IDs to a JSON file\n",
    "ensembl_ids_filepath = 'output_files/protein_atlas_ensembl_ids.json'\n",
    "with open(ensembl_ids_filepath, 'w') as f:\n",
    "    json.dump(ensembl_ids, f)\n",
    "\n",
    "# Check the first 5 Ensembl IDs\n",
    "ensembl_ids[:5], ensembl_ids_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting statsmodels\n",
      "  Downloading statsmodels-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from scipy) (1.26.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (2.2.0)\n",
      "Collecting patsy>=0.5.4 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Downloading scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy, patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 scipy-1.12.0 statsmodels-0.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output_files/fisher_test_results.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install scipy statsmodels\n",
    "from scipy.stats import fisher_exact\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Load all genelists using file paths for the gene lists\n",
    "genelist_filepaths = {f'Genelist{i}': f'genelists/Genelist{i}.txt' for i in range(1, 7)}\n",
    "\n",
    "# Paths to the input files\n",
    "cell_types_to_ensembl_filepath = 'output_files/cell_types_to_ensembl.json'\n",
    "protein_atlas_ensembl_ids_filepath = 'output_files/protein_atlas_ensembl_ids.json'\n",
    "\n",
    "# Load the Protein Atlas Ensembl IDs\n",
    "with open(protein_atlas_ensembl_ids_filepath, 'r') as f:\n",
    "    protein_atlas_ensembl_ids = set(json.load(f))\n",
    "\n",
    "# Load the mapping of cell types to Ensembl IDs\n",
    "with open(cell_types_to_ensembl_filepath, 'r') as f:\n",
    "    cell_types_to_ensembl = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "fisher_test_results = defaultdict(dict)\n",
    "\n",
    "# Perform Fisher's Exact Test for each genelist\n",
    "for genelist_name, genelist_filepath in genelist_filepaths.items():\n",
    "    # Load the genelist\n",
    "    with open(genelist_filepath, 'r') as f:\n",
    "        genelist = set(line.strip().strip('\"') for line in f.readlines())\n",
    "\n",
    "    # Total number of genes in the genelist and in the Protein Atlas\n",
    "    total_genes_genelist = len(genelist)\n",
    "    total_genes_atlas = len(protein_atlas_ensembl_ids)\n",
    "\n",
    "    p_values = []\n",
    "\n",
    "    # Perform the test for each cell type\n",
    "    for cell_type, ensembl_ids in cell_types_to_ensembl.items():\n",
    "        ensembl_ids_set = set(ensembl_ids)\n",
    "\n",
    "        # Count of genes in both the genelist and the cell type\n",
    "        count_in_both = len(genelist.intersection(ensembl_ids_set))\n",
    "        count_in_genelist_not_cell_type = len(genelist.difference(ensembl_ids_set))\n",
    "        count_in_cell_type_not_genelist = len(ensembl_ids_set.difference(genelist))\n",
    "        count_in_neither = total_genes_atlas - (count_in_both + count_in_genelist_not_cell_type + count_in_cell_type_not_genelist)\n",
    "\n",
    "        # Construct the contingency table\n",
    "        table = [\n",
    "            [count_in_both, count_in_cell_type_not_genelist],\n",
    "            [count_in_genelist_not_cell_type, count_in_neither]\n",
    "        ]\n",
    "\n",
    "        # Perform Fisher's Exact Test\n",
    "        odds_ratio, p_value = fisher_exact(table, alternative='greater')\n",
    "        p_values.append(p_value)\n",
    "\n",
    "        # Store the results without adjusted p-values first\n",
    "        fisher_test_results[genelist_name][cell_type] = {\n",
    "            'p_value': p_value,\n",
    "            'odds_ratio': odds_ratio,\n",
    "            'count_in_both': count_in_both,\n",
    "            'count_in_genelist_not_cell_type': count_in_genelist_not_cell_type,\n",
    "            'count_in_cell_type_not_genelist': count_in_cell_type_not_genelist,\n",
    "            'count_in_neither': count_in_neither\n",
    "        }\n",
    "\n",
    "    # Adjust p-values using the Benjamini-Hochberg procedure\n",
    "    _, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    # Store the adjusted p-values in the results\n",
    "    for (cell_type, _), adj_p_value in zip(fisher_test_results[genelist_name].items(), pvals_corrected):\n",
    "        fisher_test_results[genelist_name][cell_type]['adjusted_p_value'] = adj_p_value\n",
    "    \n",
    "    # Sort results by adjusted p_value in ascending order\n",
    "    fisher_test_results[genelist_name] = dict(sorted(fisher_test_results[genelist_name].items(), key=lambda x: x[1].get('adjusted_p_value', 1)))\n",
    "\n",
    "# Save the results to a JSON file\n",
    "results_filepath = 'output_files/fisher_test_results.json'\n",
    "with open(results_filepath, 'w') as f:\n",
    "    json.dump(fisher_test_results, f)\n",
    "\n",
    "results_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.26.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.12.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Genelist1': [{'cell_type': 'esophagus',\n",
       "   'p_value': 7.601491563693231e-83,\n",
       "   'odds_ratio': 38.03038138332256,\n",
       "   'count_in_both': 81,\n",
       "   'count_in_genelist_not_cell_type': 119,\n",
       "   'count_in_cell_type_not_genelist': 351,\n",
       "   'count_in_neither': 19611,\n",
       "   'adjusted_p_value': 1.0262013610985863e-80},\n",
       "  {'cell_type': 'Suprabasal keratinocytes',\n",
       "   'p_value': 4.524016635921081e-70,\n",
       "   'odds_ratio': 26.866237987563593,\n",
       "   'count_in_both': 78,\n",
       "   'count_in_genelist_not_cell_type': 122,\n",
       "   'count_in_cell_type_not_genelist': 464,\n",
       "   'count_in_neither': 19498,\n",
       "   'adjusted_p_value': 3.0537112292467296e-68},\n",
       "  {'cell_type': 'vagina',\n",
       "   'p_value': 1.6908530223420254e-62,\n",
       "   'odds_ratio': 65.7748344370861,\n",
       "   'count_in_both': 49,\n",
       "   'count_in_genelist_not_cell_type': 151,\n",
       "   'count_in_cell_type_not_genelist': 98,\n",
       "   'count_in_neither': 19864,\n",
       "   'adjusted_p_value': 7.608838600539114e-61},\n",
       "  {'cell_type': 'Basal keratinocytes',\n",
       "   'p_value': 7.369658263665469e-38,\n",
       "   'odds_ratio': 21.508183825208718,\n",
       "   'count_in_both': 43,\n",
       "   'count_in_genelist_not_cell_type': 157,\n",
       "   'count_in_cell_type_not_genelist': 251,\n",
       "   'count_in_neither': 19711,\n",
       "   'adjusted_p_value': 2.4872596639870958e-36},\n",
       "  {'cell_type': 'skin 1',\n",
       "   'p_value': 8.6332271896158e-28,\n",
       "   'odds_ratio': 10.425534896757918,\n",
       "   'count_in_both': 46,\n",
       "   'count_in_genelist_not_cell_type': 154,\n",
       "   'count_in_cell_type_not_genelist': 556,\n",
       "   'count_in_neither': 19406,\n",
       "   'adjusted_p_value': 2.330971341196266e-26}],\n",
       " 'Genelist2': [{'cell_type': 'Leydig cells',\n",
       "   'p_value': 2.1788500557207554e-12,\n",
       "   'odds_ratio': 7.860914148576415,\n",
       "   'count_in_both': 22,\n",
       "   'count_in_genelist_not_cell_type': 178,\n",
       "   'count_in_cell_type_not_genelist': 309,\n",
       "   'count_in_neither': 19653,\n",
       "   'adjusted_p_value': 2.9414475752230195e-10},\n",
       "  {'cell_type': 'Fibroblasts',\n",
       "   'p_value': 1.0161292677628894e-10,\n",
       "   'odds_ratio': 6.352030434397947,\n",
       "   'count_in_both': 22,\n",
       "   'count_in_genelist_not_cell_type': 178,\n",
       "   'count_in_cell_type_not_genelist': 381,\n",
       "   'count_in_neither': 19581,\n",
       "   'adjusted_p_value': 6.858872557399503e-09},\n",
       "  {'cell_type': 'Astrocytes',\n",
       "   'p_value': 1.9242371893637563e-09,\n",
       "   'odds_ratio': 3.5055032797323658,\n",
       "   'count_in_both': 37,\n",
       "   'count_in_genelist_not_cell_type': 163,\n",
       "   'count_in_cell_type_not_genelist': 1214,\n",
       "   'count_in_neither': 18748,\n",
       "   'adjusted_p_value': 8.659067352136903e-08},\n",
       "  {'cell_type': 'Peritubular cells',\n",
       "   'p_value': 1.2083477944302134e-08,\n",
       "   'odds_ratio': 5.573777118986659,\n",
       "   'count_in_both': 19,\n",
       "   'count_in_genelist_not_cell_type': 181,\n",
       "   'count_in_cell_type_not_genelist': 369,\n",
       "   'count_in_neither': 19593,\n",
       "   'adjusted_p_value': 4.0781738062019703e-07},\n",
       "  {'cell_type': 'Oligodendrocyte precursor cells',\n",
       "   'p_value': 1.848262349070478e-07,\n",
       "   'odds_ratio': 2.8124168671011485,\n",
       "   'count_in_both': 39,\n",
       "   'count_in_genelist_not_cell_type': 161,\n",
       "   'count_in_cell_type_not_genelist': 1583,\n",
       "   'count_in_neither': 18379,\n",
       "   'adjusted_p_value': 4.990308342490291e-06}],\n",
       " 'Genelist3': [],\n",
       " 'Genelist4': [],\n",
       " 'Genelist5': [],\n",
       " 'Genelist6': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install statsmodels\n",
    "import json\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Load Fisher test results\n",
    "results_filepath = 'output_files/fisher_test_results.json'\n",
    "with open(results_filepath, 'r') as file:\n",
    "    fisher_test_results = json.load(file)\n",
    "\n",
    "# Extract insights from the Fisher test results\n",
    "insights = {}\n",
    "p_value_threshold = 0.05  # Adjusted p-value threshold\n",
    "\n",
    "for genelist, cell_types in fisher_test_results.items():\n",
    "    associations = []\n",
    "    p_values = []\n",
    "    for cell_type, stats in cell_types.items():\n",
    "        p_value = stats.get('p_value', 1)\n",
    "        count_in_both = stats.get('count_in_both', 0)\n",
    "        count_in_genelist_not_cell_type = stats.get('count_in_genelist_not_cell_type', 0)\n",
    "        count_in_cell_type_not_genelist = stats.get('count_in_cell_type_not_genelist', 0)\n",
    "        count_in_neither = stats.get('count_in_neither', 0)\n",
    "\n",
    "        # Calculate the odds ratio\n",
    "        odds_ratio = (count_in_both * count_in_neither) / (count_in_genelist_not_cell_type * count_in_cell_type_not_genelist) if count_in_genelist_not_cell_type and count_in_cell_type_not_genelist else float('inf')\n",
    "\n",
    "        associations.append({\n",
    "            'cell_type': cell_type,\n",
    "            'p_value': p_value,\n",
    "            'odds_ratio': odds_ratio,  # Include the odds ratio\n",
    "            'count_in_both': count_in_both,\n",
    "            'count_in_genelist_not_cell_type': count_in_genelist_not_cell_type,\n",
    "            'count_in_cell_type_not_genelist': count_in_cell_type_not_genelist,\n",
    "            'count_in_neither': count_in_neither\n",
    "        })\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    # Adjust p-values using the Benjamini-Hochberg procedure\n",
    "    reject, pvals_corrected, _, _ = multipletests(p_values, alpha=p_value_threshold, method='fdr_bh')\n",
    "\n",
    "    # Store only associations with an adjusted p-value below the threshold and less than 1.0\n",
    "    significant_associations = []\n",
    "    for association, adj_p_value, rej in zip(associations, pvals_corrected, reject):\n",
    "        if rej and adj_p_value < 1.0:\n",
    "            association['adjusted_p_value'] = adj_p_value\n",
    "            significant_associations.append(association)\n",
    "\n",
    "    # Sort the significant associations by adjusted p_value in ascending order\n",
    "    significant_associations.sort(key=lambda x: x.get('adjusted_p_value', 1))\n",
    "    insights[genelist] = significant_associations\n",
    "\n",
    "# Write the insights to a JSON file\n",
    "output_filepath = 'output_files/fisher_test_insights.json'\n",
    "with open(output_filepath, 'w') as f:\n",
    "    json.dump(insights, f)\n",
    "\n",
    "# Displaying the first few insights for review\n",
    "{key: insights[key][:5] for key in insights.keys()}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
