{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proteinatlas.tsv.zip already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os # yes or no\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_files_from_hpa(url, max_size_gb=1, subfolder=\"downloaded_hpa_files\"):\n",
    "    # Create the subfolder if it doesn't exist\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "\n",
    "    # Convert the max size from GB to bytes\n",
    "    max_size_bytes = max_size_gb * 1e9\n",
    "\n",
    "    # Make an HTTP GET request to the provided URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure we got a successful response\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Search for all <a> tags with the specified href structure\n",
    "    links = soup.find_all('a', href=True)\n",
    "\n",
    "    # Base URL to prepend to relative file paths\n",
    "    base_url = \"https://www.proteinatlas.org\"\n",
    "\n",
    "    for link in links:\n",
    "        file_url = link['href']\n",
    "        if file_url.endswith('.zip'):  # Check if the link is to a .zip file\n",
    "            full_url = base_url + file_url\n",
    "\n",
    "            # Extract filename from the URL\n",
    "            filename = file_url.split('/')[-1]\n",
    "\n",
    "            # Create the full path to save the file\n",
    "            save_path = os.path.join(subfolder, filename)\n",
    "            \n",
    "            # Check if the file already exists\n",
    "            if os.path.exists(save_path):\n",
    "                print(f\"{filename} already exists. Skipping download.\")\n",
    "                continue\n",
    "\n",
    "            if filename == \"proteinatlas.tsv.zip\":\n",
    "                # Check file size without downloading the entire file\n",
    "                file_response = requests.head(full_url)\n",
    "                file_size = int(file_response.headers.get('Content-Length', 0))\n",
    "\n",
    "                if file_size <= max_size_bytes:\n",
    "                    # Download the file if it's within the size limit\n",
    "                    print(f\"Downloading {filename}...\")\n",
    "                    file_response = requests.get(full_url, stream=True)\n",
    "                    with open(save_path, 'wb') as file:\n",
    "                        for chunk in file_response.iter_content(chunk_size=8192):\n",
    "                            file.write(chunk)\n",
    "                    print(f\"{filename} downloaded!\")\n",
    "                else:\n",
    "                    print(f\"Skipping {filename} as it exceeds the size limit.\")\n",
    "\n",
    "# Example usage\n",
    "download_files_from_hpa(\"https://www.proteinatlas.org/about/download\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped files to unzipped_folder\n",
      "Gene,\"Gene synonym\",Ensembl,\"Gene description\",Uniprot,Chromosome,Position,\"Protein class\",\"Biological process\",\"Molecular function\",\"Disease involvement\",Evidence,\"HPA evidence\",\"UniProt evidence\",\"NeXtProt evidence\",\"RNA tissue specificity\",\"RNA tissue distribution\",\"RNA tissue specificity score\",\"RNA tissue specific nTPM\",\"RNA single cell type specificity\",\"RNA single cell type distribution\",\"RNA single cell type specificity score\",\"RNA single cell type specific nTPM\",\"RNA cancer specificity\",\"RNA cancer distribution\",\"RNA cancer specificity score\",\"RNA cancer specific FPKM\",\"RNA brain regional specificity\",\"RNA brain regional distribution\",\"RNA brain regional specificity score\",\"RNA brain regional specific nTPM\",\"RNA blood cell specificity\",\"RNA blood cell distribution\",\"RNA blood cell specificity score\",\"RNA blood cell specific nTPM\",\"RNA blood lineage specificity\",\"RNA blood lineage distribution\",\"RNA blood lineage specificity score\",\"RNA blood lineage specific nTPM\",\"RNA cell line specificity\",\"RNA cell line distribution\",\"RNA cell line specificity score\",\"RNA cell line specific nTPM\",\"RNA tissue cell type enrichment\",\"RNA mouse brain regional specificity\",\"RNA mouse brain regional distribution\",\"RNA mouse brain regional specificity score\",\"RNA mouse brain regional specific nTPM\",\"RNA pig brain regional specificity\",\"RNA pig brain regional distribution\",\"RNA pig brain regional specificity score\",\"RNA pig brain regional specific nTPM\",Antibody,\"Reliability (IH)\",\"Reliability (Mouse Brain)\",\"Reliability (IF)\",\"Subcellular location\",\"Secretome location\",\"Secretome function\",\"CCD Protein\",\"CCD Transcript\",\"Blood concentration - Conc. blood IM [pg/L]\",\"Blood concentration - Conc. blood MS [pg/L]\",\"Blood expression cluster\",\"Tissue expression cluster\",\"Brain expression cluster\",\"Cell line expression cluster\",\"Single cell expression cluster\",Interactions,\"Subcellular main location\",\"Subcellular additional location\",\"Antibody RRID\",\"Pathology prognostics - Breast cancer\",\"Pathology prognostics - Cervical cancer\",\"Pathology prognostics - Colorectal cancer\",\"Pathology prognostics - Endometrial cancer\",\"Pathology prognostics - Glioma\",\"Pathology prognostics - Head and neck cancer\",\"Pathology prognostics - Liver cancer\",\"Pathology prognostics - Lung cancer\",\"Pathology prognostics - Melanoma\",\"Pathology prognostics - Ovarian cancer\",\"Pathology prognostics - Pancreatic cancer\",\"Pathology prognostics - Prostate cancer\",\"Pathology prognostics - Renal cancer\",\"Pathology prognostics - Stomach cancer\",\"Pathology prognostics - Testis cancer\",\"Pathology prognostics - Thyroid cancer\",\"Pathology prognostics - Urothelial cancer\"\n",
      "TSPAN6,\"T245, TM4SF6, TSPAN-6\",ENSG00000000003,\"Tetraspanin 6\",O43657,X,100627108-100639991,\"Predicted intracellular proteins, Predicted membrane proteins\",,,,\"Evidence at protein level\",\"Evidence at transcript level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Low tissue specificity\",\"Detected in many\",,,\"Cell type enriched\",\"Detected in many\",6,\"Late spermatids: 1752.2\",\"Low cancer specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,\"Immune cell enhanced\",\"Detected in some\",,\"naive CD4 T-cell: 2.1\",\"Lineage enriched\",\"Detected in single\",7,\"T-cells: 2.1\",\"Low cancer specificity\",\"Detected in many\",,,\"Liver - Hepatocytes, Testis - Late spermatids, Thyroid - Thyroid glandular cells\",\"Low region specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,HPA004109,Approved,,Approved,\"Nucleoli fibrillar center,Cell Junctions,Cytosol\",,,NA,NA,,,\"Cluster 43: Non-specific - Transcription & Translation\",\"Cluster 8: Ciliated cells - Cilium organization\",\"Cluster 3: Choroid plexus - Cilium\",\"Cluster 53: Squamous epithelial cells - Keratinization\",\"Cluster 36: Late spermatids - Unknown function\",,\"Cell Junctions, Cytosol\",\"Nucleoli fibrillar center\",\"HPA004109: AB_1080301\",\"unprognostic (7.71e-2)\",\"unprognostic (8.97e-2)\",\"unprognostic (3.56e-2)\",\"unprognostic (2.57e-1)\",\"unprognostic (2.71e-3)\",\"unprognostic (5.93e-2)\",\"unprognostic (1.04e-1)\",\"unprognostic (1.09e-2)\",\"unprognostic (1.19e-2)\",\"unprognostic (1.80e-3)\",\"unprognostic (2.04e-3)\",\"unprognostic (8.76e-2)\",\"unprognostic (3.83e-3)\",\"unprognostic (4.28e-2)\",\"unprognostic (1.14e-1)\",\"unprognostic (2.24e-1)\",\"unprognostic (9.54e-3)\"\n",
      "TNMD,\"BRICD4, ChM1L, myodulin, TEM, tendin\",ENSG00000000005,Tenomodulin,Q9H2S6,X,100584936-100599885,\"Predicted membrane proteins\",,,,\"Evidence at protein level\",\"Evidence at transcript level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Tissue enhanced\",\"Detected in some\",,\"adipose tissue: 20.4;breast: 12.5;seminal vesicle: 25.2\",\"Cell type enriched\",\"Detected in some\",6,\"Adipocytes: 72.2\",\"Low cancer specificity\",\"Detected in some\",,,\"Low region specificity\",\"Detected in some\",,,\"Not detected in immune cells\",\"Not detected\",,,\"Not detected\",\"Not detected\",,,\"Group enriched\",\"Detected in some\",5,\"testis cancer: 1.1;Uterine cancer: 1.3\",\"Skeletal muscle - Fibroblasts\",\"Low region specificity\",\"Detected in many\",,,\"Low region specificity\",\"Detected in many\",,,\"HPA034961, HPA055634\",Uncertain,,,,,,NA,NA,,,,\"Cluster 7: Adipose tissue - Mixed function\",\"Cluster 36: Choroid plexus - Mixed function\",\"Cluster 34: Testis cancer - Unknown function\",\"Cluster 41: Adipocytes & Endothelial cells - Mixed function\",1,,,\"HPA034961: AB_10670285, HPA055634: AB_2682868\",\"unprognostic (3.60e-2)\",,\"unprognostic (9.84e-3)\",\"unprognostic (3.19e-2)\",\"unprognostic (7.77e-3)\",,\"unprognostic (2.42e-1)\",,,\"unprognostic (2.15e-1)\",\"unprognostic (2.36e-2)\",\"unprognostic (1.37e-1)\",\"unprognostic (9.40e-2)\",\"unprognostic (9.60e-4)\",\"unprognostic (6.82e-2)\",\"unprognostic (5.67e-2)\",\"unprognostic (1.48e-1)\"\n",
      "DPM1,\"CDGIE, MPDS\",ENSG00000000419,\"Dolichyl-phosphate mannosyltransferase subunit 1, catalytic\",O60762,20,50934867-50959140,\"Disease related genes, Enzymes, Human disease related genes, Metabolic proteins, Plasma proteins, Potential drug targets, Predicted intracellular proteins\",,\"Glycosyltransferase, Transferase\",\"Congenital disorder of glycosylation, Congenital muscular dystrophy, Disease variant, Dystroglycanopathy\",\"Evidence at protein level\",\"Evidence at transcript level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Low tissue specificity\",\"Detected in all\",,,\"Cell type enhanced\",\"Detected in all\",,\"Basal respiratory cells: 234.7;Syncytiotrophoblasts: 265.5\",\"Low cancer specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,\"Low immune cell specificity\",\"Detected in all\",,,\"Low lineage specificity\",\"Detected in all\",,,\"Low cancer specificity\",\"Detected in all\",,,,\"Low region specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,HPA051818,Approved,,,,,,NA,NA,,,\"Cluster 33: Non-specific - ATP binding\",\"Cluster 35: Non-specific - Mitochondria\",\"Cluster 21: Non-specific - Metabolism\",\"Cluster 62: Non-specific - Plasma proteins\",\"Cluster 35: Respiratory epithelial cells - Unknown function\",3,,,\"HPA051818: AB_2681624\",\"unprognostic (2.21e-2)\",\"unprognostic (4.94e-2)\",\"unprognostic (1.16e-1)\",\"unprognostic (4.24e-3)\",\"unprognostic (1.65e-1)\",\"unprognostic (3.27e-2)\",\"prognostic unfavorable (1.94e-6)\",\"unprognostic (1.10e-1)\",\"unprognostic (7.49e-2)\",\"unprognostic (2.53e-2)\",\"unprognostic (1.29e-2)\",\"unprognostic (3.61e-2)\",\"unprognostic (3.02e-3)\",\"unprognostic (4.98e-2)\",\"unprognostic (2.59e-1)\",\"unprognostic (3.58e-1)\",\"unprognostic (2.74e-1)\"\n",
      "SCYL3,\"PACE-1, PACE1\",ENSG00000000457,\"SCY1 like pseudokinase 3\",Q8IZE3,1,169849631-169894267,\"Enzymes, Predicted intracellular proteins\",,,,\"Evidence at protein level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Evidence at protein level\",\"Low tissue specificity\",\"Detected in all\",,,\"Low cell type specificity\",\"Detected in many\",,,\"Low cancer specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,\"Low immune cell specificity\",\"Detected in all\",,,\"Low lineage specificity\",\"Detected in all\",,,\"Low cancer specificity\",\"Detected in all\",,,\"Liver - Hepatocytes\",\"Low region specificity\",\"Detected in all\",,,\"Low region specificity\",\"Detected in all\",,,\"HPA005624, HPA072383\",Approved,,Supported,\"Golgi apparatus,Cytosol\",,,NA,NA,,,\"Cluster 5: Non-specific - Cell proliferation\",\"Cluster 1: Liver & Kidney - Metabolism\",\"Cluster 50: Non-specific - Nucleic acid binding\",\"Cluster 45: Non-specific - Nuclear processes\",\"Cluster 55: Non-specific - Transcription\",4,\"Golgi apparatus, Cytosol\",,\"HPA005624: AB_1854916, HPA072383: \",\"unprognostic (2.35e-1)\",\"unprognostic (1.25e-1)\",\"unprognostic (7.53e-2)\",\"unprognostic (8.36e-2)\",\"unprognostic (7.13e-2)\",\"unprognostic (2.72e-3)\",\"unprognostic (1.31e-1)\",\"unprognostic (2.12e-2)\",\"unprognostic (2.85e-2)\",\"unprognostic (7.17e-2)\",\"unprognostic (8.80e-2)\",\"unprognostic (9.88e-2)\",\"unprognostic (1.20e-3)\",\"unprognostic (3.54e-1)\",\"unprognostic (1.75e-1)\",\"unprognostic (4.60e-2)\",\"prognostic favorable (8.85e-4)\"\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Function to unzip a file\n",
    "def unzip_file(zip_file_path, output_folder_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_folder_path)\n",
    "        print(f\"Unzipped files to {output_folder_path}\")\n",
    "\n",
    "# Unzip the file\n",
    "unzip_file('downloaded_hpa_files/proteinatlas.tsv.zip', 'unzipped_folder')\n",
    "\n",
    "# Read the first 5 lines of the unzipped .tsv file\n",
    "try:\n",
    "    with open('unzipped_folder/proteinatlas.tsv', 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 5:\n",
    "                break\n",
    "            print(line.strip().replace('\\t', ','))\n",
    "except FileNotFoundError:\n",
    "    print(\"The file 'proteinatlas.tsv' was not found in the 'unzipped_folder'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as ontology/uHAF_marker_reference.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_file_from_github(url, save_path, folder_name=\"ontology\"):\n",
    "    # Create folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Define the full path to save the file\n",
    "    full_save_path = os.path.join(folder_name, save_path)\n",
    "\n",
    "    # Download the file\n",
    "    response = requests.get(url)\n",
    "    with open(full_save_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(f\"File downloaded and saved as {full_save_path}\")\n",
    "\n",
    "# URL to the hECA marker gene annotation file\n",
    "heca_url = \"https://github.com/XuegongLab/hECA/raw/main/UHAF/uHAF%20marker%20reference.xlsx\"\n",
    "\n",
    "# Name of the file to save\n",
    "heca_save_path = \"uHAF_marker_reference.xlsx\"\n",
    "\n",
    "# Download the file\n",
    "download_file_from_github(heca_url, heca_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPA tissue to marker JSON saved at: ontology/json_output/HPA_tissue_to_marker.json\n",
      "HPA cell_type to marker JSON saved at: ontology/json_output/HPA_cell_type_to_marker.json\n",
      "hECA tissue to marker JSON saved at: ontology/json_output/hECA_tissue_to_marker.json\n",
      "hECA cell_type to marker JSON saved at: ontology/json_output/hECA_cell_type_to_marker.json\n"
     ]
    }
   ],
   "source": [
    "def convert_to_json(file_path, output_directory, is_hpa):\n",
    "    # Create dictionaries for tissues/organs and cell types to markers\n",
    "    tissue_to_marker = defaultdict(set)\n",
    "    cell_type_to_marker = defaultdict(set)\n",
    "\n",
    "    if is_hpa:\n",
    "        # Read the HPA Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Iterate through the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            tissue = row['Tissue']  # 'Tissue' column used for HPA\n",
    "            cell_type = row['Cell type']\n",
    "            marker = row['Marker']\n",
    "            \n",
    "            tissue_to_marker[tissue.strip()].add(marker.strip())\n",
    "            cell_type_to_marker[cell_type.strip()].add(marker.strip())\n",
    "    else:\n",
    "        # Read the hECA Excel file\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "\n",
    "        # Iterate over each sheet\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            df = pd.read_excel(xls, sheet_name)\n",
    "\n",
    "            # Check for 'Marker' or 'marker' column\n",
    "            marker_column = 'Marker' if 'Marker' in df.columns else 'marker'\n",
    "            if marker_column not in df.columns:\n",
    "                raise KeyError(f\"Column 'Marker' or 'marker' not found in sheet {sheet_name}\")\n",
    "\n",
    "            # Iterate through the DataFrame\n",
    "            for index, row in df.iterrows():\n",
    "                tissue = sheet_name  # Use the sheet name as the tissue/organ for hECA\n",
    "                cell_type = row['cell_type']\n",
    "                if pd.isnull(cell_type):\n",
    "                    continue  # Skip rows where cell type is NaN or None\n",
    "            cell_type = str(cell_type).strip()  # Convert to string and strip whitespace\n",
    "        \n",
    "            markers = set(map(str.strip, str(row[marker_column]).split(',')))  # Convert to string and split\n",
    "\n",
    "            tissue_to_marker[tissue.strip()].update(markers)\n",
    "            cell_type_to_marker[cell_type].update(markers)\n",
    "\n",
    "    # Save to JSON files\n",
    "    for category, cat_to_marker in [('tissue', tissue_to_marker), ('cell_type', cell_type_to_marker)]:\n",
    "        json_file_path = os.path.join(output_directory, f\"{'HPA' if is_hpa else 'hECA'}_{category}_to_marker.json\")\n",
    "        with open(json_file_path, 'w') as json_file:\n",
    "            json.dump({k: list(v) for k, v in cat_to_marker.items()}, json_file, indent=4)\n",
    "        print(f\"{'HPA' if is_hpa else 'hECA'} {category} to marker JSON saved at: {json_file_path}\")\n",
    "\n",
    "# Correct file paths before running the function\n",
    "hpa_excel_file_path = 'ontology/HPA_marker_reference.xlsx'\n",
    "heca_excel_file_path = 'ontology/uHAF_marker_reference.xlsx'\n",
    "output_directory = 'ontology/json_output'\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Convert and save the HPA Excel file to JSON\n",
    "convert_to_json(hpa_excel_file_path, output_directory, is_hpa=True)\n",
    "\n",
    "# Convert and save the hECA Excel file to JSON\n",
    "convert_to_json(heca_excel_file_path, output_directory, is_hpa=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'basal cell', 'keratinocyte', 'b cell', 'exocrine cell', 'melanocyte', 'proximal convoluted tubule', 'sertoli cell', 'rod cell', 'horizontal cell', 'ductal cell', 'paneth cell', 't cell', 'granulocyte', 'muller cell', 'goblet cell', 'endothelial cell', 'enterocyte', 'endocrine cell', 'dendritic cell', 'distal convoluted tubule', 'fibroblast', 'erythroid cell', 'macrophage', 'smooth muscle cell', 'club cell/bronchiolar exocrine cell/clara cell', 'cardiomyocyte cell', 'cone cell', 'monocyte', 'collecting duct', 'hepatocyte'}\n",
      "\n",
      "\n",
      "basal cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "keratinocyte: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "b cell: {'common_markers': 2, 'percentage_common_markers_heca': 25.0, 'percentage_common_markers_hpa': 66.7}\n",
      "exocrine cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "melanocyte: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "proximal convoluted tubule: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "sertoli cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "rod cell: {'common_markers': 2, 'percentage_common_markers_heca': 50.0, 'percentage_common_markers_hpa': 66.7}\n",
      "horizontal cell: {'common_markers': 3, 'percentage_common_markers_heca': 100.0, 'percentage_common_markers_hpa': 100.0}\n",
      "ductal cell: {'common_markers': 1, 'percentage_common_markers_heca': 25.0, 'percentage_common_markers_hpa': 33.3}\n",
      "paneth cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "t cell: {'common_markers': 1, 'percentage_common_markers_heca': 2.8, 'percentage_common_markers_hpa': 33.3}\n",
      "granulocyte: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "muller cell: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "goblet cell: {'common_markers': 2, 'percentage_common_markers_heca': 14.3, 'percentage_common_markers_hpa': 66.7}\n",
      "endothelial cell: {'common_markers': 4, 'percentage_common_markers_heca': 10.8, 'percentage_common_markers_hpa': 100.0}\n",
      "enterocyte: {'common_markers': 2, 'percentage_common_markers_heca': 10.0, 'percentage_common_markers_hpa': 25.0}\n",
      "endocrine cell: {'common_markers': 1, 'percentage_common_markers_heca': 33.3, 'percentage_common_markers_hpa': 33.3}\n",
      "dendritic cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "distal convoluted tubule: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "fibroblast: {'common_markers': 2, 'percentage_common_markers_heca': 7.4, 'percentage_common_markers_hpa': 66.7}\n",
      "erythroid cell: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "macrophage: {'common_markers': 2, 'percentage_common_markers_heca': 6.9, 'percentage_common_markers_hpa': 40.0}\n",
      "smooth muscle cell: {'common_markers': 2, 'percentage_common_markers_heca': 10.0, 'percentage_common_markers_hpa': 66.7}\n",
      "club cell/bronchiolar exocrine cell/clara cell: {'common_markers': 2, 'percentage_common_markers_heca': 22.2, 'percentage_common_markers_hpa': 66.7}\n",
      "cardiomyocyte cell: {'common_markers': 3, 'percentage_common_markers_heca': 42.9, 'percentage_common_markers_hpa': 75.0}\n",
      "cone cell: {'common_markers': 2, 'percentage_common_markers_heca': 28.6, 'percentage_common_markers_hpa': 66.7}\n",
      "monocyte: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "collecting duct: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n",
      "hepatocyte: {'common_markers': 0, 'percentage_common_markers_heca': 0.0, 'percentage_common_markers_hpa': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def create_custom_mapping():\n",
    "    \"\"\"\n",
    "    Create a custom mapping from plural forms (common in HPA) to singular forms (common in hECA).\n",
    "    This helps in aligning cell types between the two datasets.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'b cells': 'b cell',\n",
    "        'dendritic cells': 'dendritic cell',\n",
    "        'endothelial cells': 'endothelial cell',\n",
    "        'fibroblasts': 'fibroblast',\n",
    "        'granulocytes': 'granulocyte',\n",
    "        'macrophages': 'macrophage',\n",
    "        'monocytes': 'monocyte',\n",
    "        'smooth muscle cells': 'smooth muscle cell',\n",
    "        't cells': 't cell',\n",
    "        'enterocytes': 'enterocyte',\n",
    "        'goblet cells': 'goblet cell',\n",
    "        'paneth cells': 'paneth cell',\n",
    "        'enterocytes': 'enterocyte',\n",
    "        'cone photoreceptor cells': 'cone cell',\n",
    "        'horizontal cells': 'horizontal cell',\n",
    "        'muller glia cells': 'muller cell',\n",
    "        'rod photoreceptor cells': 'rod cell',\n",
    "        'cardiomyocytes': 'cardiomyocyte cell',\n",
    "        'collecting duct cells': 'collecting duct',\n",
    "        'distal tubular cells': 'distal convoluted tubule',\n",
    "        'proximal tubular cells': 'proximal convoluted tubule',\n",
    "        'erythroid cells': 'erythroid cell',\n",
    "        'hepatocytes': 'hepatocyte',\n",
    "        'kupffer cells': 'kupffer cell',\n",
    "        'bronchial epithelium, club cells': 'club cell/bronchiolar exocrine cell/clara cell',\n",
    "        'alveolar cells type 1': 'type I alveolar cell/type I pneumocyte',\n",
    "        'alveolar cells type 2': 'type II alveolar cell/type II pneumocyte',\n",
    "        'exocrine glandular cells': 'exocrine cell',\n",
    "        'ductal cells': 'ductal cell',\n",
    "        'pancreatic endocrine cells': 'endocrine cell',\n",
    "        'exocrine glandular cells': 'exocrine cell',\n",
    "        'basal glandular cells': 'basal cell',\n",
    "        'suprabasal keratinocytes': 'keratinocyte',\n",
    "        'melanocytes': 'melanocyte',\n",
    "        'paneth cells ': 'paneth cell',\n",
    "        'sertoli cells': 'sertoli cell',\n",
    "        'spermatogonia ': 'differentiating spermatogonia',\n",
    "        'spermatogonia ': 'differentiated spermatogonia',\n",
    "        # Add more mappings as needed based on the cell types in your datasets\n",
    "    }\n",
    "\n",
    "def normalize_name(name, custom_mapping):\n",
    "    \"\"\"\n",
    "    Normalize cell type names by applying custom mappings for known discrepancies.\n",
    "    \"\"\"\n",
    "    normalized = name.strip().lower().replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "    # Convert plural to singular by checking custom mapping\n",
    "    normalized = custom_mapping.get(normalized, normalized)\n",
    "    return normalized\n",
    "\n",
    "def load_and_normalize_data(file_path, custom_mapping):\n",
    "    \"\"\"\n",
    "    Load JSON data from a file, normalize cell type names using the custom mapping,\n",
    "    and return a dictionary with normalized cell type names as keys.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Normalize cell type names and return a new dictionary\n",
    "    return {normalize_name(key, custom_mapping): set(value) for key, value in data.items()}\n",
    "\n",
    "# Define your custom mapping\n",
    "custom_mapping = create_custom_mapping()\n",
    "\n",
    "# Load and normalize the data from JSON files\n",
    "heca_cell_type_to_marker = load_and_normalize_data('ontology/json_output/hECA_cell_type_to_marker.json', custom_mapping)\n",
    "hpa_cell_type_to_marker = load_and_normalize_data('ontology/json_output/HPA_cell_type_to_marker.json', custom_mapping)\n",
    "\n",
    "common_cell_types = set(heca_cell_type_to_marker.keys()) & set(hpa_cell_type_to_marker.keys())\n",
    "print(common_cell_types)\n",
    "print('\\n')\n",
    "\n",
    "similarity_stats = {}\n",
    "\n",
    "for cell_type in common_cell_types:\n",
    "    heca_markers = heca_cell_type_to_marker[cell_type]\n",
    "    hpa_markers = hpa_cell_type_to_marker[cell_type]\n",
    "    common_markers = heca_markers & hpa_markers\n",
    "    \n",
    "    total_markers_heca = len(heca_markers)\n",
    "    total_markers_hpa = len(hpa_markers)\n",
    "    total_common_markers = len(common_markers)\n",
    "    \n",
    "    similarity_stats[cell_type] = {\n",
    "        \"common_markers\": total_common_markers,\n",
    "        \"percentage_common_markers_heca\": round((total_common_markers / total_markers_heca) * 100, 1) if total_markers_heca else 0,\n",
    "        \"percentage_common_markers_hpa\": round((total_common_markers / total_markers_hpa) * 100, 1) if total_markers_hpa else 0,\n",
    "    }\n",
    "\n",
    "# Display the similarity statistics\n",
    "for cell_type, stats in similarity_stats.items():\n",
    "    print(f\"{cell_type}: {stats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dendritic cell', 'proximal convoluted tubule', 'smooth muscle cell', 'ductal cell', 'rod cell', 'fibroblast', 'paneth cell', 't cell', 'endothelial cell', 'basal cell', 'collecting duct', 'muller cell', 'distal convoluted tubule', 'club cell/bronchiolar exocrine cell/clara cell', 'exocrine cell', 'b cell', 'cardiomyocyte cell', 'urothelial cell', 'horizontal cell', 'goblet cell', 'sertoli cell', 'cone cell', 'erythroid cell', 'keratinocyte'}\n",
      "\n",
      "\n",
      "smooth muscle cell: {'common_markers': 2, 'percentage_common_markers_heca': 10.0, 'percentage_common_markers_hpa': 66.7}\n",
      "ductal cell: {'common_markers': 1, 'percentage_common_markers_heca': 25.0, 'percentage_common_markers_hpa': 33.3}\n",
      "rod cell: {'common_markers': 2, 'percentage_common_markers_heca': 50.0, 'percentage_common_markers_hpa': 66.7}\n",
      "fibroblast: {'common_markers': 2, 'percentage_common_markers_heca': 7.4, 'percentage_common_markers_hpa': 66.7}\n",
      "t cell: {'common_markers': 1, 'percentage_common_markers_heca': 2.8, 'percentage_common_markers_hpa': 33.3}\n",
      "endothelial cell: {'common_markers': 4, 'percentage_common_markers_heca': 10.8, 'percentage_common_markers_hpa': 100.0}\n",
      "muller cell: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n",
      "club cell/bronchiolar exocrine cell/clara cell: {'common_markers': 2, 'percentage_common_markers_heca': 22.2, 'percentage_common_markers_hpa': 66.7}\n",
      "b cell: {'common_markers': 2, 'percentage_common_markers_heca': 25.0, 'percentage_common_markers_hpa': 66.7}\n",
      "cardiomyocyte cell: {'common_markers': 3, 'percentage_common_markers_heca': 42.9, 'percentage_common_markers_hpa': 75.0}\n",
      "horizontal cell: {'common_markers': 3, 'percentage_common_markers_heca': 100.0, 'percentage_common_markers_hpa': 100.0}\n",
      "goblet cell: {'common_markers': 2, 'percentage_common_markers_heca': 14.3, 'percentage_common_markers_hpa': 66.7}\n",
      "cone cell: {'common_markers': 2, 'percentage_common_markers_heca': 28.6, 'percentage_common_markers_hpa': 66.7}\n",
      "keratinocyte: {'common_markers': 3, 'percentage_common_markers_heca': 75.0, 'percentage_common_markers_hpa': 100.0}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def create_custom_mapping():\n",
    "    \"\"\"\n",
    "    Define a mapping for cell type synonyms and specific exceptions.\n",
    "    This function now focuses on special cases not handled by automatic pluralization and normalization.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        # Explicit mappings for cases with missing words or different word ending\n",
    "        'bronchial epithelium, club cells': 'club cell/bronchiolar exocrine cell/clara cell',\n",
    "        'alveolar cells type 1': 'type I alveolar cell/type I pneumocyte',\n",
    "        'alveolar cells type 2': 'type II alveolar cell/type II pneumocyte',\n",
    "        'cone photoreceptor cells': 'cone cell',\n",
    "        'muller glia cells': 'muller cell',\n",
    "        'rod photoreceptor cells': 'rod cell',\n",
    "        'cardiomyocytes': 'cardiomyocyte cell',\n",
    "        'collecting duct cells': 'collecting duct',\n",
    "        'distal tubular cells': 'distal convoluted tubule',\n",
    "        'proximal tubular cells': 'proximal convoluted tubule',\n",
    "        'exocrine glandular cells': 'exocrine cell',\n",
    "        'basal glandular cells': 'basal cell',\n",
    "        'suprabasal keratinocytes': 'keratinocyte',\n",
    "        'spermatogonia ': 'differentiating spermatogonia',\n",
    "        'spermatogonia ': 'differentiated spermatogonia',\n",
    "        # Add or adjust mappings as needed for specific cases\n",
    "    }\n",
    "\n",
    "def normalize_name(name, custom_mapping):\n",
    "    \"\"\"\n",
    "    Normalize cell type names by applying custom mappings for known discrepancies, \n",
    "    including automatic adjustments for case, hyphens, underscores, \n",
    "    and handling singular/plural forms relevant to cell types.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and replace hyphens/underscores with spaces\n",
    "    normalized = name.strip().lower().replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "\n",
    "    # Apply custom mappings first for specific synonyms and exceptions\n",
    "    normalized = custom_mapping.get(normalized, normalized)\n",
    "\n",
    "    # Automatically handle plural forms with basic English rules, tailored for cell types\n",
    "    if normalized.endswith('ies'):\n",
    "        normalized = re.sub('ies$', 'y', normalized)  # Correct rule for converting plurals ending in 'ies' to 'y'\n",
    "    elif normalized.endswith('es'):\n",
    "        # Correct handling for plurals ending in 'es', which might be common for certain biological terms\n",
    "        normalized = normalized[:-2]  # Removes the 'es', e.g., \"paneth cells\" to \"paneth cell\"\n",
    "    elif normalized.endswith('s') and not normalized.endswith('ss'):\n",
    "        normalized = normalized[:-1]  # General case for plurals not ending in 'ss', e.g., \"cells\" to \"cell\"\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def load_and_normalize_data(file_path, custom_mapping):\n",
    "    \"\"\"\n",
    "    Load JSON data from a file, normalize cell type names using the custom mapping,\n",
    "    and return a dictionary with normalized cell type names as keys.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Normalize cell type names and return a new dictionary\n",
    "    return {normalize_name(key, custom_mapping): set(value) for key, value in data.items()}\n",
    "\n",
    "# Define your custom mapping\n",
    "custom_mapping = create_custom_mapping()\n",
    "\n",
    "# Load and normalize the data from JSON files\n",
    "heca_cell_type_to_marker = load_and_normalize_data('ontology/json_output/hECA_cell_type_to_marker.json', custom_mapping)\n",
    "hpa_cell_type_to_marker = load_and_normalize_data('ontology/json_output/HPA_cell_type_to_marker.json', custom_mapping)\n",
    "\n",
    "common_cell_types = set(heca_cell_type_to_marker.keys()) & set(hpa_cell_type_to_marker.keys())\n",
    "print(common_cell_types)\n",
    "print('\\n')\n",
    "\n",
    "similarity_stats = {}\n",
    "\n",
    "for cell_type in common_cell_types:\n",
    "    heca_markers = heca_cell_type_to_marker[cell_type]\n",
    "    hpa_markers = hpa_cell_type_to_marker[cell_type]\n",
    "    common_markers = heca_markers & hpa_markers\n",
    "    \n",
    "    total_markers_heca = len(heca_markers)\n",
    "    total_markers_hpa = len(hpa_markers)\n",
    "    total_common_markers = len(common_markers)\n",
    "    \n",
    "    # Only add to similarity_stats if total_common_markers is greater than 0\n",
    "    if total_common_markers > 0:\n",
    "        similarity_stats[cell_type] = {\n",
    "            \"common_markers\": total_common_markers,\n",
    "            \"percentage_common_markers_heca\": round((total_common_markers / total_markers_heca) * 100, 1) if total_markers_heca else 0,\n",
    "            \"percentage_common_markers_hpa\": round((total_common_markers / total_markers_hpa) * 100, 1) if total_markers_hpa else 0,\n",
    "        }\n",
    "\n",
    "for cell_type, stats in similarity_stats.items():\n",
    "    print(f\"{cell_type}: {stats}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Data written to output_files/cell_types_to_ensembl.json\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "class GeneExpressionAtlas:\n",
    "    def __init__(self, data_path, columns_to_check):\n",
    "        self.data_path = data_path\n",
    "        self.columns_to_check = columns_to_check\n",
    "        self.cell_types_to_ensembl = defaultdict(set)\n",
    "\n",
    "    def extract_cell_types(self):\n",
    "        df = pd.read_csv(self.data_path, sep='\\t')\n",
    "        for index, row in df.iterrows():\n",
    "            ensembl_id = row['Ensembl']\n",
    "            for col in self.columns_to_check:\n",
    "                cell_type_data = row[col]\n",
    "                if pd.notna(cell_type_data):\n",
    "                    for item in cell_type_data.split(';'):\n",
    "                        cell_type = item.split(':')[0].strip()\n",
    "                        self.cell_types_to_ensembl[cell_type].add(ensembl_id)\n",
    "        return self.cell_types_to_ensembl\n",
    "\n",
    "    def to_json(self, output_path):\n",
    "        # Convert sets to lists for JSON serialization\n",
    "        for cell_type, ensembl_ids in self.cell_types_to_ensembl.items():\n",
    "            self.cell_types_to_ensembl[cell_type] = list(ensembl_ids)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(self.cell_types_to_ensembl, f)\n",
    "        return output_path\n",
    "\n",
    "class HPA(GeneExpressionAtlas):\n",
    "    def __init__(self, data_path):\n",
    "        columns_to_check = [\n",
    "            \"RNA tissue specific nTPM\",\n",
    "            \"RNA single cell type specific nTPM\",\n",
    "            \"RNA blood cell specific nTPM\",\n",
    "            \"RNA blood lineage specific nTPM\"\n",
    "        ]\n",
    "        super().__init__(data_path, columns_to_check)\n",
    "\n",
    "class hECA(GeneExpressionAtlas):\n",
    "    # hECA specific implementation would go here, if needed.\n",
    "    pass\n",
    "\n",
    "# Example usage for HPA\n",
    "hpa_data_path = \"unzipped_folder/proteinatlas.tsv\"\n",
    "hpa = HPA(hpa_data_path)\n",
    "\n",
    "# Extract cell types and associated Ensembl Gene IDs\n",
    "hpa_cell_types_to_ensembl = hpa.extract_cell_types()\n",
    "\n",
    "# Directory where the aggregated results will be saved\n",
    "output_directory = \"output_files\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Write the results to a JSON file\n",
    "json_file_path = hpa.to_json(f'{output_directory}/cell_types_to_ensembl.json')\n",
    "print(f\"Data written to {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy<2,>=1.26.0 (from pandas)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.0 pytz-2024.1 tzdata-2023.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2153/1811752549.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hpa_cell_types_to_ensembl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_types_to_ensembl\n\u001b[1;32m     24\u001b[0m intersection \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell_type \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhpa_cell_types_to_ensembl\u001b[49m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cell_type \u001b[38;5;129;01min\u001b[39;00m heca_cell_type_to_marker:\n\u001b[1;32m     27\u001b[0m         intersection[cell_type] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHPA_Ensembl_IDs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(hpa_cell_types_to_ensembl[cell_type]),\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhECA_markers\u001b[39m\u001b[38;5;124m'\u001b[39m: heca_cell_type_to_marker[cell_type]\n\u001b[1;32m     30\u001b[0m         }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hpa_cell_types_to_ensembl' is not defined"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "class GeneExpressionAtlas:\n",
    "    def __init__(self, data_path, columns_to_check, custom_mapping=None):\n",
    "        self.data_path = data_path\n",
    "        self.columns_to_check = columns_to_check\n",
    "        self.custom_mapping = custom_mapping if custom_mapping else create_custom_mapping()\n",
    "        self.cell_types_to_ensembl = defaultdict(set)\n",
    "\n",
    "    def extract_cell_types(self):\n",
    "        df = pd.read_csv(self.data_path, sep='\\t')\n",
    "        for _, row in df.iterrows():\n",
    "            ensembl_id = row['Ensembl']\n",
    "            for col in self.columns_to_check:\n",
    "                cell_type_data = row[col]\n",
    "                if pd.notna(cell_type_data):\n",
    "                    for item in cell_type_data.split(';'):\n",
    "                        cell_type, _ = item.split(':')  # Assume format is \"cell_type:expression\"\n",
    "                        normalized_cell_type = normalize_name(cell_type, self.custom_mapping)\n",
    "                        self.cell_types_to_ensembl[normalized_cell_type].add(ensembl_id)\n",
    "        return self.cell_types_to_ensembl\n",
    "\n",
    "intersection = {}\n",
    "for cell_type in hpa_cell_types_to_ensembl:\n",
    "    if cell_type in heca_cell_type_to_marker:\n",
    "        intersection[cell_type] = {\n",
    "            'HPA_Ensembl_IDs': list(hpa_cell_types_to_ensembl[cell_type]),\n",
    "            'hECA_markers': heca_cell_type_to_marker[cell_type]\n",
    "        }\n",
    "\n",
    "# Print the intersection\n",
    "for cell_type, data in intersection.items():\n",
    "    print(f\"Cell Type: {cell_type}\")\n",
    "    print(f\"HPA Ensembl Gene IDs: {data['HPA_Ensembl_IDs']}\")\n",
    "    print(f\"hECA Marker Genes: {data['hECA_markers']}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: goatools in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (1.3.11)\n",
      "Requirement already satisfied: networkx in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (3.2.1)\n",
      "Requirement already satisfied: scipy in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: statsmodels in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (0.14.1)\n",
      "Requirement already satisfied: mygene in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (3.2.2)\n",
      "Requirement already satisfied: matplotlib in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (3.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: xlsxwriter in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (3.1.9)\n",
      "Requirement already satisfied: openpyxl in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (3.1.2)\n",
      "Requirement already satisfied: docopt in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (0.6.2)\n",
      "Requirement already satisfied: pydot in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (2.0.0)\n",
      "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (2.31.0)\n",
      "Requirement already satisfied: rich in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from goatools) (13.7.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: biothings-client>=0.2.6 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from mygene) (0.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests->goatools) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests->goatools) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests->goatools) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests->goatools) (2023.11.17)\n",
      "Requirement already satisfied: et-xmlfile in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from openpyxl->goatools) (1.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from rich->goatools) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from rich->goatools) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->goatools) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Example usage - paths need to be specified for your GO OBO file and gene2go association file\\ngene_expression_atlas = GeneExpressionAtlas(\\n    data_path=\"path/to/proteinatlas.tsv\",\\n    columns_to_check=[\"your\", \"columns\"],\\n    go_obo_path=\"path/to/go-basic.obo\",\\n    gene2go_path=\"path/to/gene2go\"\\n)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install pandas goatools networkx scipy statsmodels mygene matplotlib\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from goatools import obo_parser\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n",
    "from goatools.associations import read_ncbi_gene2go\n",
    "import mygene\n",
    "import networkx as nx\n",
    "from goatools.obo_parser import GODag\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class GeneExpressionAtlas:\n",
    "    def __init__(self, data_path, columns_to_check, custom_mapping=None, go_obo_path=None, gene2go_path=None):\n",
    "        self.data_path = data_path\n",
    "        self.columns_to_check = columns_to_check\n",
    "        self.custom_mapping = custom_mapping if custom_mapping else create_custom_mapping()\n",
    "        self.cell_types_to_ensembl = defaultdict(set)\n",
    "        self.go_obo_path = go_obo_path  # Path to the GO OBO file\n",
    "        self.gene2go_path = gene2go_path  # Path to the gene2go association file\n",
    "        self.go_dag = None if not go_obo_path else obo_parser.GODag(go_obo_path)\n",
    "        self.gene2go = None if not gene2go_path else read_ncbi_gene2go(gene2go_path, taxids=[9606])  # Assuming human genes\n",
    "        super().__init__(data_path, columns_to_check)\n",
    "        self.go_dag = GODag(go_obo_path)\n",
    "\n",
    "    def extract_cell_types(self):\n",
    "        df = pd.read_csv(self.data_path, sep='\\t')\n",
    "        for _, row in df.iterrows():\n",
    "            ensembl_id = row['Ensembl']\n",
    "            for col in self.columns_to_check:\n",
    "                cell_type_data = row[col]\n",
    "                if pd.notna(cell_type_data):\n",
    "                    for item in cell_type_data.split(';'):\n",
    "                        cell_type, _ = item.split(':')  # Assume format is \"cell_type:expression\"\n",
    "                        normalized_cell_type = normalize_name(cell_type, self.custom_mapping)\n",
    "                        self.cell_types_to_ensembl[normalized_cell_type].add(ensembl_id)\n",
    "        return self.cell_types_to_ensembl\n",
    "\n",
    "    def perform_go_enrichment_for_cell_type(self, cell_type_genes, background_gene_list):\n",
    "        # Assuming cell_type_genes is a list of NCBI IDs for a specific cell type\n",
    "        goeaobj = GOEnrichmentStudyNS(\n",
    "            background_gene_list, \n",
    "            ns2assoc, \n",
    "            self.go_dag,\n",
    "            propagate_counts=False,\n",
    "            alpha=0.05,\n",
    "            methods=['fdr_bh']\n",
    "        )\n",
    "        goea_results_all = goeaobj.run_study(cell_type_genes)\n",
    "        goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.05]  # Filter for significant results\n",
    "        return goea_results_sig\n",
    "\n",
    "    def convert_ensembl_to_ncbi(self, ensembl_ids):\n",
    "        mg = mygene.MyGeneInfo()\n",
    "        query_results = mg.querymany(ensembl_ids, scopes='ensembl.gene', fields='entrezgene', species='human', as_dataframe=True)\n",
    "        return {result['query']: result.get('entrezgene') for result in query_results if 'entrezgene' in result}\n",
    "        '''\n",
    "        # Mapping from Ensembl ID to NCBI Gene ID\n",
    "        ensembl_to_ncbi = {}\n",
    "        for index, row in query_results.iterrows():\n",
    "            if 'entrezgene' in row and pd.notnull(row['entrezgene']):\n",
    "                ensembl_to_ncbi[index] = str(int(row['entrezgene']))  # Convert float NaN to int for valid IDs, and then to string if needed\n",
    "        \n",
    "        # Replace Ensembl IDs with NCBI IDs where a mapping exists\n",
    "        converted_ids = [ensembl_to_ncbi.get(ensembl_id, ensembl_id) for ensembl_id in ensembl_ids]\n",
    "        \n",
    "        return converted_ids\n",
    "        '''\n",
    "    def report_enrichment_results(self, cell_type, results):\n",
    "        \"\"\"\n",
    "        Process and prepare GO enrichment analysis results for visualization.\n",
    "        \n",
    "        :param cell_type: The cell type for which GO enrichment was performed.\n",
    "        :param results: A list of dictionaries containing GO enrichment results,\n",
    "                        each with keys 'GO Term', 'p-value', 'adjusted p-value', and 'genes'.\n",
    "        \"\"\"\n",
    "        # Filter for significant results\n",
    "        sig_results = [res for res in results if res['adjusted p-value'] < 0.05]\n",
    "        \n",
    "        # Initialize a directed graph for visualization\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        for res in sig_results:\n",
    "            go_term = res['GO Term']\n",
    "            G.add_node(go_term, **{'p_value': res['p-value'], 'adjusted_p_value': res['adjusted p-value'], 'genes': res['genes']})\n",
    "            \n",
    "            # Add edges based on the GO hierarchy\n",
    "            for parent in self.go_dag[go_term].get_all_parents():\n",
    "                if parent in self.go_dag:\n",
    "                    G.add_edge(parent, go_term)\n",
    "        \n",
    "        # Optionally, return the graph for further processing or visualization\n",
    "        return G\n",
    "\n",
    "def visualize_go_dag(G):\n",
    "    pos = nx.spring_layout(G, seed=42)  # For consistent layout\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=5000, node_color='lightblue', font_size=10, font_weight='bold')\n",
    "    plt.title('GO Terms Hierarchical Structure')\n",
    "    plt.show()\n",
    "    \n",
    "'''\n",
    "# Example usage - paths need to be specified for your GO OBO file and gene2go association file\n",
    "gene_expression_atlas = GeneExpressionAtlas(\n",
    "    data_path=\"path/to/proteinatlas.tsv\",\n",
    "    columns_to_check=[\"your\", \"columns\"],\n",
    "    go_obo_path=\"path/to/go-basic.obo\",\n",
    "    gene2go_path=\"path/to/gene2go\"\n",
    ")\n",
    "'''\n",
    "# After extracting cell types and genes, you can perform GO enrichment\n",
    "# gene_expression_atlas.extract_cell_types()\n",
    "# You need to provide a background_gene_list, which could be all genes in your dataset\n",
    "# gene_expression_atlas.perform_go_enrichment(background_gene_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_files/cell_types_for_all_genelists.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Function to load a genelist from a file\n",
    "def load_genelist(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Remove quotes and strip whitespace from each line\n",
    "        return [line.strip().strip('\"') for line in f.read().splitlines()]\n",
    "\n",
    "# Load the cell_types_to_ensembl.json file\n",
    "cell_types_to_ensembl_filepath = 'output_files/cell_types_to_ensembl.json'\n",
    "with open(cell_types_to_ensembl_filepath, 'r') as f:\n",
    "    cell_types_to_ensembl = json.load(f)\n",
    "\n",
    "# Load all genelists using file paths for the gene lists\n",
    "genelists_files = [f'genelists/Genelist{i}.txt' for i in range(1, 7)]\n",
    "\n",
    "# Initialize a dictionary to store cell type frequencies for all genelists\n",
    "cell_types_for_all_genelists = {}\n",
    "\n",
    "# Loop through each genelist file\n",
    "for i, genelist_file in enumerate(genelists_files, 1):\n",
    "    # Load the current genelist\n",
    "    genelist = load_genelist(genelist_file)\n",
    "    \n",
    "    # Initialize a defaultdict to store the results for the current genelist\n",
    "    cell_types_for_genelist = defaultdict(int)\n",
    "\n",
    "    # Identify cell types associated with the genes in the current genelist\n",
    "    for cell_type, ensembl_ids in cell_types_to_ensembl.items():\n",
    "        for ensembl_id in genelist:\n",
    "            if ensembl_id in ensembl_ids:\n",
    "                cell_types_for_genelist[cell_type] += 1\n",
    "\n",
    "    # Store the results for the current genelist\n",
    "    cell_types_for_all_genelists[f'Genelist{i}'] = cell_types_for_genelist\n",
    "\n",
    "# Save the aggregated results to a JSON file\n",
    "cell_types_for_all_genelists_file = 'output_files/cell_types_for_all_genelists.json'\n",
    "with open(cell_types_for_all_genelists_file, 'w') as f:\n",
    "    json.dump(cell_types_for_all_genelists, f)\n",
    "\n",
    "cell_types_for_all_genelists_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ENSG00000000003',\n",
       "  'ENSG00000000005',\n",
       "  'ENSG00000000419',\n",
       "  'ENSG00000000457',\n",
       "  'ENSG00000000460'],\n",
       " 'output_files/protein_atlas_ensembl_ids.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the protein atlas data\n",
    "protein_atlas_filepath = 'unzipped_folder/proteinatlas.tsv'\n",
    "protein_atlas_df = pd.read_csv(protein_atlas_filepath, sep='\\t')\n",
    "\n",
    "# Extract the Ensembl IDs from the 'Gene' column\n",
    "ensembl_ids = protein_atlas_df['Ensembl'].unique().tolist()\n",
    "\n",
    "# Save the Ensembl IDs to a JSON file\n",
    "ensembl_ids_filepath = 'output_files/protein_atlas_ensembl_ids.json'\n",
    "with open(ensembl_ids_filepath, 'w') as f:\n",
    "    json.dump(ensembl_ids, f)\n",
    "\n",
    "# Check the first 5 Ensembl IDs\n",
    "ensembl_ids[:5], ensembl_ids_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting statsmodels\n",
      "  Downloading statsmodels-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from scipy) (1.26.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (2.2.0)\n",
      "Collecting patsy>=0.5.4 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Downloading scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy, patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 scipy-1.12.0 statsmodels-0.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output_files/fisher_test_results.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install scipy statsmodels\n",
    "from scipy.stats import fisher_exact\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Load all genelists using file paths for the gene lists\n",
    "genelist_filepaths = {f'Genelist{i}': f'genelists/Genelist{i}.txt' for i in range(1, 7)}\n",
    "\n",
    "# Paths to the input files\n",
    "cell_types_to_ensembl_filepath = 'output_files/cell_types_to_ensembl.json'\n",
    "protein_atlas_ensembl_ids_filepath = 'output_files/protein_atlas_ensembl_ids.json'\n",
    "\n",
    "# Load the Protein Atlas Ensembl IDs\n",
    "with open(protein_atlas_ensembl_ids_filepath, 'r') as f:\n",
    "    protein_atlas_ensembl_ids = set(json.load(f))\n",
    "\n",
    "# Load the mapping of cell types to Ensembl IDs\n",
    "with open(cell_types_to_ensembl_filepath, 'r') as f:\n",
    "    cell_types_to_ensembl = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "fisher_test_results = defaultdict(dict)\n",
    "\n",
    "# Perform Fisher's Exact Test for each genelist\n",
    "for genelist_name, genelist_filepath in genelist_filepaths.items():\n",
    "    # Load the genelist\n",
    "    with open(genelist_filepath, 'r') as f:\n",
    "        genelist = set(line.strip().strip('\"') for line in f.readlines())\n",
    "\n",
    "    # Total number of genes in the genelist and in the Protein Atlas\n",
    "    total_genes_genelist = len(genelist)\n",
    "    total_genes_atlas = len(protein_atlas_ensembl_ids)\n",
    "\n",
    "    p_values = []\n",
    "\n",
    "    # Perform the test for each cell type\n",
    "    for cell_type, ensembl_ids in cell_types_to_ensembl.items():\n",
    "        ensembl_ids_set = set(ensembl_ids)\n",
    "\n",
    "        # Count of genes in both the genelist and the cell type\n",
    "        count_in_both = len(genelist.intersection(ensembl_ids_set))\n",
    "        count_in_genelist_not_cell_type = len(genelist.difference(ensembl_ids_set))\n",
    "        count_in_cell_type_not_genelist = len(ensembl_ids_set.difference(genelist))\n",
    "        count_in_neither = total_genes_atlas - (count_in_both + count_in_genelist_not_cell_type + count_in_cell_type_not_genelist)\n",
    "\n",
    "        # Construct the contingency table\n",
    "        table = [\n",
    "            [count_in_both, count_in_cell_type_not_genelist],\n",
    "            [count_in_genelist_not_cell_type, count_in_neither]\n",
    "        ]\n",
    "\n",
    "        # Perform Fisher's Exact Test\n",
    "        odds_ratio, p_value = fisher_exact(table, alternative='greater')\n",
    "        p_values.append(p_value)\n",
    "\n",
    "        # Store the results without adjusted p-values first\n",
    "        fisher_test_results[genelist_name][cell_type] = {\n",
    "            'p_value': p_value,\n",
    "            'odds_ratio': odds_ratio,\n",
    "            'count_in_both': count_in_both,\n",
    "            'count_in_genelist_not_cell_type': count_in_genelist_not_cell_type,\n",
    "            'count_in_cell_type_not_genelist': count_in_cell_type_not_genelist,\n",
    "            'count_in_neither': count_in_neither\n",
    "        }\n",
    "\n",
    "    # Adjust p-values using the Benjamini-Hochberg procedure\n",
    "    _, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    # Store the adjusted p-values in the results\n",
    "    for (cell_type, _), adj_p_value in zip(fisher_test_results[genelist_name].items(), pvals_corrected):\n",
    "        fisher_test_results[genelist_name][cell_type]['adjusted_p_value'] = adj_p_value\n",
    "    \n",
    "    # Sort results by adjusted p_value in ascending order\n",
    "    fisher_test_results[genelist_name] = dict(sorted(fisher_test_results[genelist_name].items(), key=lambda x: x[1].get('adjusted_p_value', 1)))\n",
    "\n",
    "# Save the results to a JSON file\n",
    "results_filepath = 'output_files/fisher_test_results.json'\n",
    "with open(results_filepath, 'w') as f:\n",
    "    json.dump(fisher_test_results, f)\n",
    "\n",
    "results_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.26.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.12.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Genelist1': [{'cell_type': 'esophagus',\n",
       "   'p_value': 7.601491563693231e-83,\n",
       "   'odds_ratio': 38.03038138332256,\n",
       "   'count_in_both': 81,\n",
       "   'count_in_genelist_not_cell_type': 119,\n",
       "   'count_in_cell_type_not_genelist': 351,\n",
       "   'count_in_neither': 19611,\n",
       "   'adjusted_p_value': 1.0262013610985863e-80},\n",
       "  {'cell_type': 'Suprabasal keratinocytes',\n",
       "   'p_value': 4.524016635921081e-70,\n",
       "   'odds_ratio': 26.866237987563593,\n",
       "   'count_in_both': 78,\n",
       "   'count_in_genelist_not_cell_type': 122,\n",
       "   'count_in_cell_type_not_genelist': 464,\n",
       "   'count_in_neither': 19498,\n",
       "   'adjusted_p_value': 3.0537112292467296e-68},\n",
       "  {'cell_type': 'vagina',\n",
       "   'p_value': 1.6908530223420254e-62,\n",
       "   'odds_ratio': 65.7748344370861,\n",
       "   'count_in_both': 49,\n",
       "   'count_in_genelist_not_cell_type': 151,\n",
       "   'count_in_cell_type_not_genelist': 98,\n",
       "   'count_in_neither': 19864,\n",
       "   'adjusted_p_value': 7.608838600539114e-61},\n",
       "  {'cell_type': 'Basal keratinocytes',\n",
       "   'p_value': 7.369658263665469e-38,\n",
       "   'odds_ratio': 21.508183825208718,\n",
       "   'count_in_both': 43,\n",
       "   'count_in_genelist_not_cell_type': 157,\n",
       "   'count_in_cell_type_not_genelist': 251,\n",
       "   'count_in_neither': 19711,\n",
       "   'adjusted_p_value': 2.4872596639870958e-36},\n",
       "  {'cell_type': 'skin 1',\n",
       "   'p_value': 8.6332271896158e-28,\n",
       "   'odds_ratio': 10.425534896757918,\n",
       "   'count_in_both': 46,\n",
       "   'count_in_genelist_not_cell_type': 154,\n",
       "   'count_in_cell_type_not_genelist': 556,\n",
       "   'count_in_neither': 19406,\n",
       "   'adjusted_p_value': 2.330971341196266e-26}],\n",
       " 'Genelist2': [{'cell_type': 'Leydig cells',\n",
       "   'p_value': 2.1788500557207554e-12,\n",
       "   'odds_ratio': 7.860914148576415,\n",
       "   'count_in_both': 22,\n",
       "   'count_in_genelist_not_cell_type': 178,\n",
       "   'count_in_cell_type_not_genelist': 309,\n",
       "   'count_in_neither': 19653,\n",
       "   'adjusted_p_value': 2.9414475752230195e-10},\n",
       "  {'cell_type': 'Fibroblasts',\n",
       "   'p_value': 1.0161292677628894e-10,\n",
       "   'odds_ratio': 6.352030434397947,\n",
       "   'count_in_both': 22,\n",
       "   'count_in_genelist_not_cell_type': 178,\n",
       "   'count_in_cell_type_not_genelist': 381,\n",
       "   'count_in_neither': 19581,\n",
       "   'adjusted_p_value': 6.858872557399503e-09},\n",
       "  {'cell_type': 'Astrocytes',\n",
       "   'p_value': 1.9242371893637563e-09,\n",
       "   'odds_ratio': 3.5055032797323658,\n",
       "   'count_in_both': 37,\n",
       "   'count_in_genelist_not_cell_type': 163,\n",
       "   'count_in_cell_type_not_genelist': 1214,\n",
       "   'count_in_neither': 18748,\n",
       "   'adjusted_p_value': 8.659067352136903e-08},\n",
       "  {'cell_type': 'Peritubular cells',\n",
       "   'p_value': 1.2083477944302134e-08,\n",
       "   'odds_ratio': 5.573777118986659,\n",
       "   'count_in_both': 19,\n",
       "   'count_in_genelist_not_cell_type': 181,\n",
       "   'count_in_cell_type_not_genelist': 369,\n",
       "   'count_in_neither': 19593,\n",
       "   'adjusted_p_value': 4.0781738062019703e-07},\n",
       "  {'cell_type': 'Oligodendrocyte precursor cells',\n",
       "   'p_value': 1.848262349070478e-07,\n",
       "   'odds_ratio': 2.8124168671011485,\n",
       "   'count_in_both': 39,\n",
       "   'count_in_genelist_not_cell_type': 161,\n",
       "   'count_in_cell_type_not_genelist': 1583,\n",
       "   'count_in_neither': 18379,\n",
       "   'adjusted_p_value': 4.990308342490291e-06}],\n",
       " 'Genelist3': [],\n",
       " 'Genelist4': [],\n",
       " 'Genelist5': [],\n",
       " 'Genelist6': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install statsmodels\n",
    "import json\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Load Fisher test results\n",
    "results_filepath = 'output_files/fisher_test_results.json'\n",
    "with open(results_filepath, 'r') as file:\n",
    "    fisher_test_results = json.load(file)\n",
    "\n",
    "# Extract insights from the Fisher test results\n",
    "insights = {}\n",
    "p_value_threshold = 0.05  # Adjusted p-value threshold\n",
    "\n",
    "for genelist, cell_types in fisher_test_results.items():\n",
    "    associations = []\n",
    "    p_values = []\n",
    "    for cell_type, stats in cell_types.items():\n",
    "        p_value = stats.get('p_value', 1)\n",
    "        count_in_both = stats.get('count_in_both', 0)\n",
    "        count_in_genelist_not_cell_type = stats.get('count_in_genelist_not_cell_type', 0)\n",
    "        count_in_cell_type_not_genelist = stats.get('count_in_cell_type_not_genelist', 0)\n",
    "        count_in_neither = stats.get('count_in_neither', 0)\n",
    "\n",
    "        # Calculate the odds ratio\n",
    "        odds_ratio = (count_in_both * count_in_neither) / (count_in_genelist_not_cell_type * count_in_cell_type_not_genelist) if count_in_genelist_not_cell_type and count_in_cell_type_not_genelist else float('inf')\n",
    "\n",
    "        associations.append({\n",
    "            'cell_type': cell_type,\n",
    "            'p_value': p_value,\n",
    "            'odds_ratio': odds_ratio,  # Include the odds ratio\n",
    "            'count_in_both': count_in_both,\n",
    "            'count_in_genelist_not_cell_type': count_in_genelist_not_cell_type,\n",
    "            'count_in_cell_type_not_genelist': count_in_cell_type_not_genelist,\n",
    "            'count_in_neither': count_in_neither\n",
    "        })\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    # Adjust p-values using the Benjamini-Hochberg procedure\n",
    "    reject, pvals_corrected, _, _ = multipletests(p_values, alpha=p_value_threshold, method='fdr_bh')\n",
    "\n",
    "    # Store only associations with an adjusted p-value below the threshold and less than 1.0\n",
    "    significant_associations = []\n",
    "    for association, adj_p_value, rej in zip(associations, pvals_corrected, reject):\n",
    "        if rej and adj_p_value < 1.0:\n",
    "            association['adjusted_p_value'] = adj_p_value\n",
    "            significant_associations.append(association)\n",
    "\n",
    "    # Sort the significant associations by adjusted p_value in ascending order\n",
    "    significant_associations.sort(key=lambda x: x.get('adjusted_p_value', 1))\n",
    "    insights[genelist] = significant_associations\n",
    "\n",
    "# Write the insights to a JSON file\n",
    "output_filepath = 'output_files/fisher_test_insights.json'\n",
    "with open(output_filepath, 'w') as f:\n",
    "    json.dump(insights, f)\n",
    "\n",
    "# Displaying the first few insights for review\n",
    "{key: insights[key][:5] for key in insights.keys()}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
